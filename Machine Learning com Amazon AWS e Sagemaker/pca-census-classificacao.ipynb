{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>inative-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       income  age          workclass  final-weight    education  \\\n",
       "0       <=50K   39          State-gov         77516    Bachelors   \n",
       "1       <=50K   50   Self-emp-not-inc         83311    Bachelors   \n",
       "2       <=50K   38            Private        215646      HS-grad   \n",
       "3       <=50K   53            Private        234721         11th   \n",
       "4       <=50K   28            Private        338409    Bachelors   \n",
       "...       ...  ...                ...           ...          ...   \n",
       "32556   <=50K   27            Private        257302   Assoc-acdm   \n",
       "32557    >50K   40            Private        154374      HS-grad   \n",
       "32558   <=50K   58            Private        151910      HS-grad   \n",
       "32559   <=50K   22            Private        201490      HS-grad   \n",
       "32560    >50K   52       Self-emp-inc        287927      HS-grad   \n",
       "\n",
       "       education-num       marital-status          occupation    relationship  \\\n",
       "0                 13        Never-married        Adm-clerical   Not-in-family   \n",
       "1                 13   Married-civ-spouse     Exec-managerial         Husband   \n",
       "2                  9             Divorced   Handlers-cleaners   Not-in-family   \n",
       "3                  7   Married-civ-spouse   Handlers-cleaners         Husband   \n",
       "4                 13   Married-civ-spouse      Prof-specialty            Wife   \n",
       "...              ...                  ...                 ...             ...   \n",
       "32556             12   Married-civ-spouse        Tech-support            Wife   \n",
       "32557              9   Married-civ-spouse   Machine-op-inspct         Husband   \n",
       "32558              9              Widowed        Adm-clerical       Unmarried   \n",
       "32559              9        Never-married        Adm-clerical       Own-child   \n",
       "32560              9   Married-civ-spouse     Exec-managerial            Wife   \n",
       "\n",
       "         race      sex  capital-gain  capital-loos  hour-per-week  \\\n",
       "0       White     Male          2174             0             40   \n",
       "1       White     Male             0             0             13   \n",
       "2       White     Male             0             0             40   \n",
       "3       Black     Male             0             0             40   \n",
       "4       Black   Female             0             0             40   \n",
       "...       ...      ...           ...           ...            ...   \n",
       "32556   White   Female             0             0             38   \n",
       "32557   White     Male             0             0             40   \n",
       "32558   White   Female             0             0             40   \n",
       "32559   White     Male             0             0             20   \n",
       "32560   White   Female         15024             0             40   \n",
       "\n",
       "      inative-country  \n",
       "0       United-States  \n",
       "1       United-States  \n",
       "2       United-States  \n",
       "3       United-States  \n",
       "4                Cuba  \n",
       "...               ...  \n",
       "32556   United-States  \n",
       "32557   United-States  \n",
       "32558   United-States  \n",
       "32559   United-States  \n",
       "32560   United-States  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "base_census = pd.read_csv('census.csv')\n",
    "colunas = []\n",
    "colunas.append('income')\n",
    "for i in range(len(base_census.columns[:-1])):\n",
    "    colunas.append(base_census.columns[i])\n",
    "base_census = base_census[colunas]\n",
    "base_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def income(text):\n",
    "    if text == ' >50K':\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>inative-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>1.0</td>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       income  age          workclass  final-weight    education  \\\n",
       "0         0.0   39          State-gov         77516    Bachelors   \n",
       "1         0.0   50   Self-emp-not-inc         83311    Bachelors   \n",
       "2         0.0   38            Private        215646      HS-grad   \n",
       "3         0.0   53            Private        234721         11th   \n",
       "4         0.0   28            Private        338409    Bachelors   \n",
       "...       ...  ...                ...           ...          ...   \n",
       "32556     0.0   27            Private        257302   Assoc-acdm   \n",
       "32557     1.0   40            Private        154374      HS-grad   \n",
       "32558     0.0   58            Private        151910      HS-grad   \n",
       "32559     0.0   22            Private        201490      HS-grad   \n",
       "32560     1.0   52       Self-emp-inc        287927      HS-grad   \n",
       "\n",
       "       education-num       marital-status          occupation    relationship  \\\n",
       "0                 13        Never-married        Adm-clerical   Not-in-family   \n",
       "1                 13   Married-civ-spouse     Exec-managerial         Husband   \n",
       "2                  9             Divorced   Handlers-cleaners   Not-in-family   \n",
       "3                  7   Married-civ-spouse   Handlers-cleaners         Husband   \n",
       "4                 13   Married-civ-spouse      Prof-specialty            Wife   \n",
       "...              ...                  ...                 ...             ...   \n",
       "32556             12   Married-civ-spouse        Tech-support            Wife   \n",
       "32557              9   Married-civ-spouse   Machine-op-inspct         Husband   \n",
       "32558              9              Widowed        Adm-clerical       Unmarried   \n",
       "32559              9        Never-married        Adm-clerical       Own-child   \n",
       "32560              9   Married-civ-spouse     Exec-managerial            Wife   \n",
       "\n",
       "         race      sex  capital-gain  capital-loos  hour-per-week  \\\n",
       "0       White     Male          2174             0             40   \n",
       "1       White     Male             0             0             13   \n",
       "2       White     Male             0             0             40   \n",
       "3       Black     Male             0             0             40   \n",
       "4       Black   Female             0             0             40   \n",
       "...       ...      ...           ...           ...            ...   \n",
       "32556   White   Female             0             0             38   \n",
       "32557   White     Male             0             0             40   \n",
       "32558   White   Female             0             0             40   \n",
       "32559   White     Male             0             0             20   \n",
       "32560   White   Female         15024             0             40   \n",
       "\n",
       "      inative-country  \n",
       "0       United-States  \n",
       "1       United-States  \n",
       "2       United-States  \n",
       "3       United-States  \n",
       "4                Cuba  \n",
       "...               ...  \n",
       "32556   United-States  \n",
       "32557   United-States  \n",
       "32558   United-States  \n",
       "32559   United-States  \n",
       "32560   United-States  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_census['income'] = base_census['income'].apply(income)\n",
    "base_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 109)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_census = pd.get_dummies(base_census,prefix=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'inative-country'], \n",
    "                            columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'inative-country'])\n",
    "base_census.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[    39,  77516,     13, ...,      1,      0,      0],\n",
       "        [    50,  83311,     13, ...,      1,      0,      0],\n",
       "        [    38, 215646,      9, ...,      1,      0,      0],\n",
       "        ...,\n",
       "        [    58, 151910,      9, ...,      1,      0,      0],\n",
       "        [    22, 201490,      9, ...,      1,      0,      0],\n",
       "        [    52, 287927,      9, ...,      1,      0,      0]]),\n",
       " (32561, 108))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = base_census.iloc[:, 1:len(base_census.columns)].values\n",
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = base_census.iloc[:, 0].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).astype('float32')\n",
    "y = np.array(y).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações do SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role:  arn:aws:iam::936535973187:role/service-role/AmazonSageMaker-ExecutionRole-20220510T125992\n",
      "Localização da base de dados de treinamento:  s3://cursoawssagemaker/datasets/census/train/census-train-data-pca\n",
      "Modelo final será salvo em:  s3://cursoawssagemaker/modelos/census/pca/output\n"
     ]
    }
   ],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = 'cursoawssagemaker'\n",
    "subpasta_modelo = 'modelos/census/pca'\n",
    "subpasta_dataset = 'datasets/census'\n",
    "key_train = 'census-train-data-pca'\n",
    "role = sagemaker.get_execution_role()\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, subpasta_dataset, key_train)\n",
    "output_location = 's3://{}/{}/output'.format(bucket, subpasta_modelo)\n",
    "print('Role: ', role)\n",
    "print('Localização da base de dados de treinamento: ', s3_train_data)\n",
    "print('Modelo final será salvo em: ', output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker.amazon.common as smac\n",
    "buffer = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buffer, X)\n",
    "buffer.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(subpasta_dataset, 'train', key_train)).upload_fileobj(buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 13:36:30 Starting - Starting the training job...\n",
      "2022-05-25 13:36:47 Starting - Preparing the instances for trainingProfilerReport-1653485790: InProgress\n",
      "............\n",
      "2022-05-25 13:38:43 Downloading - Downloading input data...\n",
      "2022-05-25 13:39:31 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'algorithm_mode': 'regular', 'subtract_mean': 'true', 'extra_components': '-1', 'force_dense': 'true', 'epochs': 1, '_log_level': 'info', '_kvstore': 'dist_sync', '_num_kv_servers': 'auto', '_num_gpus': 'auto'}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '32561', 'mini_batch_size': '200', 'num_components': '80'}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Final configuration: {'algorithm_mode': 'regular', 'subtract_mean': 'true', 'extra_components': '-1', 'force_dense': 'true', 'epochs': 1, '_log_level': 'info', '_kvstore': 'dist_sync', '_num_kv_servers': 'auto', '_num_gpus': 'auto', 'feature_dim': '32561', 'mini_batch_size': '200', 'num_components': '80'}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 WARNING 140449382917952] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-111-17.sa-east-1.compute.internal', 'TRAINING_JOB_NAME': 'pca-2022-05-25-13-36-30-274', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:sa-east-1:936535973187:training-job/pca-2022-05-25-13-36-30-274', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-7305f724ff2aedca028099405fa57a2eb44d8c956e72e54dc916ccf1c14df5d2-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'sa-east-1', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml'}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-111-17.sa-east-1.compute.internal', 'TRAINING_JOB_NAME': 'pca-2022-05-25-13-36-30-274', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:sa-east-1:936535973187:training-job/pca-2022-05-25-13-36-30-274', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-7305f724ff2aedca028099405fa57a2eb44d8c956e72e54dc916ccf1c14df5d2-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'sa-east-1', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'scheduler', 'DMLC_PS_ROOT_URI': '10.0.111.17', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-111-17.sa-east-1.compute.internal', 'TRAINING_JOB_NAME': 'pca-2022-05-25-13-36-30-274', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:sa-east-1:936535973187:training-job/pca-2022-05-25-13-36-30-274', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-7305f724ff2aedca028099405fa57a2eb44d8c956e72e54dc916ccf1c14df5d2-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'sa-east-1', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml'}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-111-17.sa-east-1.compute.internal', 'TRAINING_JOB_NAME': 'pca-2022-05-25-13-36-30-274', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:sa-east-1:936535973187:training-job/pca-2022-05-25-13-36-30-274', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-7305f724ff2aedca028099405fa57a2eb44d8c956e72e54dc916ccf1c14df5d2-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'sa-east-1', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'server', 'DMLC_PS_ROOT_URI': '10.0.111.17', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Environment: {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-111-17.sa-east-1.compute.internal', 'TRAINING_JOB_NAME': 'pca-2022-05-25-13-36-30-274', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:sa-east-1:936535973187:training-job/pca-2022-05-25-13-36-30-274', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-7305f724ff2aedca028099405fa57a2eb44d8c956e72e54dc916ccf1c14df5d2-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'sa-east-1', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'worker', 'DMLC_PS_ROOT_URI': '10.0.111.17', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34mProcess 35 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 47 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:38 INFO 140449382917952] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:39 INFO 140449382917952] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:39 INFO 140449382917952] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:39 INFO 140449382917952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:39 INFO 140449382917952] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:39 INFO 140449382917952] 108 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:39 INFO 140449382917952] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 199.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653485978.3003876, \"EndTime\": 1653485979.3384435, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 1030.7762622833252, \"count\": 1, \"min\": 1030.7762622833252, \"max\": 1030.7762622833252}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653485979.3386269, \"EndTime\": 1653485979.3386712, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:39:39.339] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1039, \"num_examples\": 1, \"num_bytes\": 92000}\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:39:39.500] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 149, \"num_examples\": 163, \"num_bytes\": 14978060}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653485979.3385653, \"EndTime\": 1653485979.5012615, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"update.time\": {\"sum\": 161.1332893371582, \"count\": 1, \"min\": 161.1332893371582, \"max\": 161.1332893371582}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:39 INFO 140449382917952] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653485979.340073, \"EndTime\": 1653485979.5029573, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 32561.0, \"count\": 1, \"min\": 32561, \"max\": 32561}, \"Total Batches Seen\": {\"sum\": 163.0, \"count\": 1, \"min\": 163, \"max\": 163}, \"Max Records Seen Between Resets\": {\"sum\": 32561.0, \"count\": 1, \"min\": 32561, \"max\": 32561}, \"Max Batches Seen Between Resets\": {\"sum\": 163.0, \"count\": 1, \"min\": 163, \"max\": 163}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 32561.0, \"count\": 1, \"min\": 32561, \"max\": 32561}, \"Number of Batches Since Last Reset\": {\"sum\": 163.0, \"count\": 1, \"min\": 163, \"max\": 163}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:39 INFO 140449382917952] #throughput_metric: host=algo-1, train throughput=199616.95228629393 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653485979.5013866, \"EndTime\": 1653485979.5352683, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 31.55994415283203, \"count\": 1, \"min\": 31.55994415283203, \"max\": 31.55994415283203}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:39:39 INFO 140449382917952] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653485979.5353317, \"EndTime\": 1653485979.5357518, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 32.99117088317871, \"count\": 1, \"min\": 32.99117088317871, \"max\": 32.99117088317871}, \"totaltime\": {\"sum\": 1443.511724472046, \"count\": 1, \"min\": 1443.511724472046, \"max\": 1443.511724472046}}}\u001b[0m\n",
      "\n",
      "2022-05-25 13:39:57 Uploading - Uploading generated training model\n",
      "2022-05-25 13:39:57 Completed - Training job completed\n",
      "Training seconds: 82\n",
      "Billable seconds: 82\n"
     ]
    }
   ],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/ecr-sa-east-1.html\n",
    "container = sagemaker.image_uris.retrieve(framework = 'pca', region = boto3.Session().region_name)\n",
    "\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html\n",
    "pca = sagemaker.estimator.Estimator(image_uri = container,\n",
    "                                    role = role,\n",
    "                                    instance_count = 1,\n",
    "                                    instance_type = 'ml.c4.xlarge',\n",
    "                                    output_path = output_location,\n",
    "                                    sagemaker_session = session)\n",
    "\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/PCA-reference.html\n",
    "pca.set_hyperparameters(feature_dim = 32561,\n",
    "                        num_components = 80,\n",
    "                        mini_batch_size = 200)\n",
    "\n",
    "pca.fit({'train': s3_train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redução da dimensionalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "pca_predictor = pca.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "pca_predictor.serializer = CSVSerializer()\n",
    "pca_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9000e+01, 7.7516e+04, 1.3000e+01, 2.1740e+03, 0.0000e+00,\n",
       "       4.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 0.0000e+00], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'projections': [{'projection': [0.0012449510395526886, 0.002343464642763138, -0.0013039950281381607, 0.000418664887547493, 0.0004079388454556465, -0.0004254486411809921, 0.0002772137522697449, -0.0004678121767938137, -0.0008481075055897236, 0.00024294480681419373, 0.0018959343433380127, -0.0004775784909725189, 0.00011449679732322693, -0.0002458728849887848, 0.0030149780213832855, -0.0020423270761966705, -0.004432309418916702, -0.0015896577388048172, 0.0026109106838703156, 0.005269220098853111, -8.162111043930054e-05, 0.00033833831548690796, 0.006753459572792053, -0.0012435587123036385, 0.0007078980561345816, 0.016528287902474403, 0.002406906336545944, -0.00607888400554657, -0.007607053965330124, 0.0011467933654785156, -0.015767782926559448, -0.00635441392660141, 0.028152629733085632, -0.048242077231407166, 0.04655647277832031, 0.0051122382283210754, -0.10033466666936874, -0.07806280255317688, -0.005875088274478912, 0.013174638152122498, -0.012452095746994019, -0.01010817289352417, 0.06980320811271667, 0.18312647938728333, 0.21708184480667114, 0.05930550396442413, -0.2971758246421814, -0.3777809739112854, 0.07952114194631577, 0.27568376064300537, 0.1624433994293213, 0.10736435651779175, 0.5027090311050415, 0.4541349411010742, 0.03533980995416641, -0.008061617612838745, -0.03117217868566513, -0.1686643362045288, -0.27816298604011536, -0.28508511185646057, -0.2850269377231598, -0.20677383244037628, -0.5702735185623169, 0.9504731893539429, -0.11656656861305237, -0.257534921169281, 0.19974780082702637, 0.33032599091529846, -0.132598876953125, 0.10815909504890442, -0.4459085464477539, 0.26608309149742126, -1.0965323448181152, 0.4590553045272827, 2.900178909301758, 0.3879241943359375, -0.8151741027832031, -89.79649353027344, -1099.917236328125, 112262.34375]}]}\n"
     ]
    }
   ],
   "source": [
    "X0_pca = pca_predictor.predict(X[0])\n",
    "print(X0_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca_predictor.predict(X[0:12000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = np.array([r['projection'] for r in X_pca['projections']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.24495104e-03,  2.34346464e-03, -1.30399503e-03, ...,\n",
       "         -8.97964935e+01, -1.09991724e+03,  1.12262344e+05],\n",
       "        [ 1.43589824e-03, -6.27957284e-04, -9.94171947e-04, ...,\n",
       "         -9.33537750e+01,  1.07425757e+03,  1.06467406e+05],\n",
       "        [-1.22067891e-03, -6.09576702e-04,  6.42577186e-04, ...,\n",
       "         -8.81579437e+01,  1.07828333e+03, -2.58675938e+04],\n",
       "        ...,\n",
       "        [ 1.46968104e-03, -7.50370324e-04, -2.14563683e-03, ...,\n",
       "         -9.44503784e+01,  1.07340918e+03,  1.34354406e+05],\n",
       "        [-1.27792172e-03, -1.41525269e-03,  1.01876631e-03, ...,\n",
       "         -8.62802887e+01, -1.09910840e+03,  2.01783438e+04],\n",
       "        [ 2.44413875e-03,  1.71445310e-04,  1.50985084e-03, ...,\n",
       "         -8.40632935e+01,  1.08143372e+03, -1.29492594e+05]]),\n",
       " (12000, 80))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca, X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos dados para o Linear Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X_pca, y[0:12000], test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treinamento = np.array(X_treinamento).astype('float32')\n",
    "y_treinamento = np.array(y_treinamento).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8400, 80), (3600, 80))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treinamento.shape, X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8400,), (3600,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treinamento.shape, y_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações do SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localização da base de dados:  s3://cursoawssagemaker/datasets/census/train/census-train-data-pca\n",
      "Modelo final será salvo em:  s3://cursoawssagemaker/modelos/census/pca/output\n"
     ]
    }
   ],
   "source": [
    "subpasta_modelo_linear = 'modelos/census/linear-learner_pca'\n",
    "subpasta_dataset = 'datasets/census'\n",
    "key = 'census-train-data_pca'\n",
    "s3_train_data_pca = 's3://{}/{}/train/{}'.format(bucket, subpasta_dataset, key)\n",
    "output_location_pca = 's3://{}/{}/output'.format(bucket, subpasta_modelo)\n",
    "print('Localização da base de dados: ', s3_train_data)\n",
    "print('Modelo final será salvo em: ', output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buffer, X_treinamento, y_treinamento)\n",
    "buffer.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(subpasta_dataset, 'train', key)).upload_fileobj(buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do Linear Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 13:47:25 Starting - Starting the training job...\n",
      "2022-05-25 13:47:52 Starting - Preparing the instances for trainingProfilerReport-1653486445: InProgress\n",
      ".........\n",
      "2022-05-25 13:49:21 Downloading - Downloading input data......\n",
      "2022-05-25 13:50:26 Training - Downloading the training image.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 INFO 140002932959040] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 INFO 140002932959040] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '80', 'num_models': '8', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 INFO 140002932959040] Final configuration: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': '80', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': '8', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 WARNING 140002932959040] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 INFO 140002932959040] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 INFO 140002932959040] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:36.798] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 34, \"num_examples\": 1, \"num_bytes\": 368000}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 INFO 140002932959040] Create Store: local\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:36.900] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 100, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 INFO 140002932959040] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f54989cf2d0>\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 INFO 140002932959040] Scaling model computed with parameters:\n",
      " {'stdev_label': None, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[2.8509164e-02 2.8776309e-02 2.7615799e-02 3.5029206e-02 4.0283758e-02\n",
      " 4.2905923e-02 4.1987911e-02 4.4794198e-02 4.1061472e-02 4.3124571e-02\n",
      " 4.4149097e-02 4.2157274e-02 4.5298763e-02 4.6465151e-02 4.6346694e-02\n",
      " 4.7934238e-02 5.1691782e-02 5.0814625e-02 5.4135293e-02 5.2268535e-02\n",
      " 5.3158320e-02 5.4530360e-02 5.6996491e-02 6.2046375e-02 7.0899032e-02\n",
      " 7.0677340e-02 6.9439545e-02 7.4270912e-02 9.1650389e-02 9.6364968e-02\n",
      " 1.0484880e-01 1.0876013e-01 1.1485967e-01 1.1641107e-01 1.2208142e-01\n",
      " 1.2538861e-01 1.3418204e-01 1.3428135e-01 1.3299339e-01 1.6039389e-01\n",
      " 1.5813789e-01 1.7031303e-01 1.7415987e-01 1.7543924e-01 1.8155108e-01\n",
      " 1.7521906e-01 1.8550199e-01 1.9021001e-01 1.9215280e-01 2.0197044e-01\n",
      " 2.0845853e-01 2.1401505e-01 2.1803480e-01 2.2619125e-01 2.3911577e-01\n",
      " 2.4725324e-01 2.6117322e-01 2.7811623e-01 2.8928825e-01 2.9617330e-01\n",
      " 3.1843928e-01 3.1903553e-01 3.2481301e-01 3.3385751e-01 3.3921334e-01\n",
      " 3.5980621e-01 3.9159185e-01 4.1451484e-01 4.2047551e-01 4.4145051e-01\n",
      " 4.9742934e-01 5.2352148e-01 5.6186217e-01 8.5536438e-01 2.5132160e+00\n",
      " 1.2187469e+01 1.3587734e+01 4.1564215e+02 7.1897119e+03 1.0362179e+05]\u001b[0m\n",
      "\u001b[34m<NDArray 80 @cpu(0)>, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[-1.04131475e-04 -1.65231497e-04  7.34354137e-04  3.74518480e-04\n",
      "  3.61809834e-05  8.44721289e-05  8.78609542e-04  3.13998054e-04\n",
      " -6.27589936e-04 -6.96585921e-05  2.80117383e-05 -3.87196851e-05\n",
      "  1.29274864e-04  1.18415352e-04  6.60148100e-04 -9.86337254e-05\n",
      "  3.35390505e-05  1.25184597e-05  9.10515082e-05  4.42633580e-04\n",
      "  5.17222274e-04 -9.99233016e-05 -2.84366717e-04  7.25564663e-04\n",
      " -9.03297972e-04  6.30210736e-04 -2.87519011e-04  5.35522006e-04\n",
      "  2.39274537e-04 -1.45620288e-04 -6.21456769e-04 -1.35146035e-03\n",
      " -1.36219512e-03 -1.68104796e-03 -1.19664997e-04  2.38697394e-03\n",
      " -9.80371144e-04  6.41767227e-04  2.97741615e-03 -4.87867248e-04\n",
      " -6.97722426e-05 -3.43232008e-04  1.13839959e-03  2.09199288e-03\n",
      "  2.01603910e-03 -3.68008250e-03  1.44624303e-03 -1.27084856e-03\n",
      " -6.71803369e-04 -1.62258570e-04  3.66584351e-03 -2.24996824e-03\n",
      "  1.25454622e-03  1.16776384e-03  3.02828150e-04 -1.88760413e-03\n",
      "  1.54185668e-03  1.53594627e-03 -2.23379885e-03 -4.34784777e-03\n",
      " -1.61488075e-03  7.05394195e-05 -5.73891960e-03 -2.02155812e-03\n",
      "  2.93933623e-03 -2.60037882e-03  4.24299622e-03 -1.93023041e-03\n",
      " -2.32081115e-03  7.86353927e-03  3.58258164e-03  1.24920299e-03\n",
      " -2.49117101e-03 -4.67813760e-03 -1.15681998e-03 -6.50556684e-02\n",
      "  2.80918926e-02  6.82234669e+00  5.89514580e+01 -1.93405914e+01]\u001b[0m\n",
      "\u001b[34m<NDArray 80 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 INFO 140002932959040] nvidia-smi: took 0.035 seconds to run.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 INFO 140002932959040] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:36 INFO 140002932959040] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486636.9708204, \"EndTime\": 1653486636.9708865, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9400.0, \"count\": 1, \"min\": 9400, \"max\": 9400}, \"Total Batches Seen\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:37.107] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 136, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.107513, \"EndTime\": 1653486637.1075773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6454476013183593, \"count\": 1, \"min\": 0.6454476013183593, \"max\": 0.6454476013183593}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.10766, \"EndTime\": 1653486637.1076822, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6661121444702148, \"count\": 1, \"min\": 0.6661121444702148, \"max\": 0.6661121444702148}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.1077485, \"EndTime\": 1653486637.1077921, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6679296722412109, \"count\": 1, \"min\": 0.6679296722412109, \"max\": 0.6679296722412109}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.1078572, \"EndTime\": 1653486637.107876, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6458181381225586, \"count\": 1, \"min\": 0.6458181381225586, \"max\": 0.6458181381225586}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.107962, \"EndTime\": 1653486637.1079817, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.503401626586914, \"count\": 1, \"min\": 0.503401626586914, \"max\": 0.503401626586914}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.1080384, \"EndTime\": 1653486637.1080556, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4847186508178711, \"count\": 1, \"min\": 0.4847186508178711, \"max\": 0.4847186508178711}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.1081111, \"EndTime\": 1653486637.108128, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4949488639831543, \"count\": 1, \"min\": 0.4949488639831543, \"max\": 0.4949488639831543}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.108193, \"EndTime\": 1653486637.108211, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5027583656311035, \"count\": 1, \"min\": 0.5027583656311035, \"max\": 0.5027583656311035}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy_objective <loss>=0.6454476013183593\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=binary_classification_cross_entropy_objective, value=0.4847186508178711\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Saved checkpoint to \"/tmp/tmpfk0n44q0/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #progress_metric: host=algo-1, completed 6.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486636.9712698, \"EndTime\": 1653486637.1245234, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17800.0, \"count\": 1, \"min\": 17800, \"max\": 17800}, \"Total Batches Seen\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Number of Batches Since Last Reset\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #throughput_metric: host=algo-1, train throughput=54753.20386901062 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:37.239] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 114, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.2394493, \"EndTime\": 1653486637.2394965, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5424151840209961, \"count\": 1, \"min\": 0.5424151840209961, \"max\": 0.5424151840209961}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.2395763, \"EndTime\": 1653486637.2395926, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5599414825439453, \"count\": 1, \"min\": 0.5599414825439453, \"max\": 0.5599414825439453}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.239639, \"EndTime\": 1653486637.239651, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5617014694213868, \"count\": 1, \"min\": 0.5617014694213868, \"max\": 0.5617014694213868}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.2396924, \"EndTime\": 1653486637.2397037, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5426191596984863, \"count\": 1, \"min\": 0.5426191596984863, \"max\": 0.5426191596984863}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.2397435, \"EndTime\": 1653486637.2397542, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.36533948516845705, \"count\": 1, \"min\": 0.36533948516845705, \"max\": 0.36533948516845705}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.2397993, \"EndTime\": 1653486637.2398112, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.36386052322387696, \"count\": 1, \"min\": 0.36386052322387696, \"max\": 0.36386052322387696}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.239852, \"EndTime\": 1653486637.2398624, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.36422808456420896, \"count\": 1, \"min\": 0.36422808456420896, \"max\": 0.36422808456420896}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.2399073, \"EndTime\": 1653486637.2399178, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3702200736999512, \"count\": 1, \"min\": 0.3702200736999512, \"max\": 0.3702200736999512}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy_objective <loss>=0.5424151840209961\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=binary_classification_cross_entropy_objective, value=0.36386052322387696\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Saved checkpoint to \"/tmp/tmpb01km1e_/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #progress_metric: host=algo-1, completed 13.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.1248755, \"EndTime\": 1653486637.249004, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 26200.0, \"count\": 1, \"min\": 26200, \"max\": 26200}, \"Total Batches Seen\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Number of Batches Since Last Reset\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #throughput_metric: host=algo-1, train throughput=67534.00665139593 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:37.407] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 157, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.407153, \"EndTime\": 1653486637.4072165, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.48610275650024415, \"count\": 1, \"min\": 0.48610275650024415, \"max\": 0.48610275650024415}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.4074016, \"EndTime\": 1653486637.407429, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5007674751281739, \"count\": 1, \"min\": 0.5007674751281739, \"max\": 0.5007674751281739}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.4074962, \"EndTime\": 1653486637.4075212, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5022283668518066, \"count\": 1, \"min\": 0.5022283668518066, \"max\": 0.5022283668518066}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.4075823, \"EndTime\": 1653486637.4076014, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.48565928649902346, \"count\": 1, \"min\": 0.48565928649902346, \"max\": 0.48565928649902346}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.4076605, \"EndTime\": 1653486637.4076781, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3422052230834961, \"count\": 1, \"min\": 0.3422052230834961, \"max\": 0.3422052230834961}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.4077392, \"EndTime\": 1653486637.4077582, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34206023025512694, \"count\": 1, \"min\": 0.34206023025512694, \"max\": 0.34206023025512694}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.407815, \"EndTime\": 1653486637.407832, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34323233032226563, \"count\": 1, \"min\": 0.34323233032226563, \"max\": 0.34323233032226563}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.4078882, \"EndTime\": 1653486637.4079072, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34384086227416993, \"count\": 1, \"min\": 0.34384086227416993, \"max\": 0.34384086227416993}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy_objective <loss>=0.48610275650024415\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=binary_classification_cross_entropy_objective, value=0.34206023025512694\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Saved checkpoint to \"/tmp/tmpljxfjw67/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.2495003, \"EndTime\": 1653486637.418509, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34600.0, \"count\": 1, \"min\": 34600, \"max\": 34600}, \"Total Batches Seen\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Number of Batches Since Last Reset\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #throughput_metric: host=algo-1, train throughput=49653.24283644604 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:37.599] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 179, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.5990922, \"EndTime\": 1653486637.599153, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45735501861572264, \"count\": 1, \"min\": 0.45735501861572264, \"max\": 0.45735501861572264}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.5992863, \"EndTime\": 1653486637.5993469, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46990218353271485, \"count\": 1, \"min\": 0.46990218353271485, \"max\": 0.46990218353271485}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.599409, \"EndTime\": 1653486637.5995362, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4709914703369141, \"count\": 1, \"min\": 0.4709914703369141, \"max\": 0.4709914703369141}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.5996604, \"EndTime\": 1653486637.5997221, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45643125152587893, \"count\": 1, \"min\": 0.45643125152587893, \"max\": 0.45643125152587893}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.5997865, \"EndTime\": 1653486637.5998135, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33459765243530276, \"count\": 1, \"min\": 0.33459765243530276, \"max\": 0.33459765243530276}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.5999012, \"EndTime\": 1653486637.5999267, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33423591232299804, \"count\": 1, \"min\": 0.33423591232299804, \"max\": 0.33423591232299804}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.6000392, \"EndTime\": 1653486637.6000617, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33522840118408204, \"count\": 1, \"min\": 0.33522840118408204, \"max\": 0.33522840118408204}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.6001766, \"EndTime\": 1653486637.600197, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33596692657470706, \"count\": 1, \"min\": 0.33596692657470706, \"max\": 0.33596692657470706}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy_objective <loss>=0.45735501861572264\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=binary_classification_cross_entropy_objective, value=0.33423591232299804\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Saved checkpoint to \"/tmp/tmpsmju4y3g/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #progress_metric: host=algo-1, completed 26.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.4188519, \"EndTime\": 1653486637.6221592, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 43000.0, \"count\": 1, \"min\": 43000, \"max\": 43000}, \"Total Batches Seen\": {\"sum\": 46.0, \"count\": 1, \"min\": 46, \"max\": 46}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Number of Batches Since Last Reset\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #throughput_metric: host=algo-1, train throughput=41283.777392918324 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:37.842] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 220, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.84291, \"EndTime\": 1653486637.8429782, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.440736083984375, \"count\": 1, \"min\": 0.440736083984375, \"max\": 0.440736083984375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.843088, \"EndTime\": 1653486637.8431118, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4515424461364746, \"count\": 1, \"min\": 0.4515424461364746, \"max\": 0.4515424461364746}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.8431768, \"EndTime\": 1653486637.8431952, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4523399620056152, \"count\": 1, \"min\": 0.4523399620056152, \"max\": 0.4523399620056152}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.843252, \"EndTime\": 1653486637.8432696, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4393784065246582, \"count\": 1, \"min\": 0.4393784065246582, \"max\": 0.4393784065246582}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.8433242, \"EndTime\": 1653486637.8433416, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3288063888549805, \"count\": 1, \"min\": 0.3288063888549805, \"max\": 0.3288063888549805}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.8435779, \"EndTime\": 1653486637.8436, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33006987380981445, \"count\": 1, \"min\": 0.33006987380981445, \"max\": 0.33006987380981445}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.8436608, \"EndTime\": 1653486637.8436782, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3287840461730957, \"count\": 1, \"min\": 0.3287840461730957, \"max\": 0.3287840461730957}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.8437319, \"EndTime\": 1653486637.8437493, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32957877731323243, \"count\": 1, \"min\": 0.32957877731323243, \"max\": 0.32957877731323243}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy_objective <loss>=0.440736083984375\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=binary_classification_cross_entropy_objective, value=0.3287840461730957\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] Saved checkpoint to \"/tmp/tmpy80hb6pu/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #progress_metric: host=algo-1, completed 33.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.6224978, \"EndTime\": 1653486637.877833, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 51400.0, \"count\": 1, \"min\": 51400, \"max\": 51400}, \"Total Batches Seen\": {\"sum\": 55.0, \"count\": 1, \"min\": 55, \"max\": 55}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Number of Batches Since Last Reset\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:37 INFO 140002932959040] #throughput_metric: host=algo-1, train throughput=32877.34653199257 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:38.064] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 185, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.0644794, \"EndTime\": 1653486638.0645468, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4284197425842285, \"count\": 1, \"min\": 0.4284197425842285, \"max\": 0.4284197425842285}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.064654, \"EndTime\": 1653486638.0646772, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43759316635131834, \"count\": 1, \"min\": 0.43759316635131834, \"max\": 0.43759316635131834}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.0647364, \"EndTime\": 1653486638.0647519, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.438238166809082, \"count\": 1, \"min\": 0.438238166809082, \"max\": 0.438238166809082}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.0648043, \"EndTime\": 1653486638.0648189, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42656603622436523, \"count\": 1, \"min\": 0.42656603622436523, \"max\": 0.42656603622436523}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.0648696, \"EndTime\": 1653486638.0648842, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32757226943969725, \"count\": 1, \"min\": 0.32757226943969725, \"max\": 0.32757226943969725}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.0649352, \"EndTime\": 1653486638.064951, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3275020866394043, \"count\": 1, \"min\": 0.3275020866394043, \"max\": 0.3275020866394043}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.065001, \"EndTime\": 1653486638.0650148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3279277420043945, \"count\": 1, \"min\": 0.3279277420043945, \"max\": 0.3279277420043945}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.0650682, \"EndTime\": 1653486638.0650814, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32786183547973635, \"count\": 1, \"min\": 0.32786183547973635, \"max\": 0.32786183547973635}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #quality_metric: host=algo-1, epoch=5, train binary_classification_cross_entropy_objective <loss>=0.4284197425842285\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=binary_classification_cross_entropy_objective, value=0.3275020866394043\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Saving model for epoch: 5\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Saved checkpoint to \"/tmp/tmpfpbxlz1r/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486637.8782337, \"EndTime\": 1653486638.0755093, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 59800.0, \"count\": 1, \"min\": 59800, \"max\": 59800}, \"Total Batches Seen\": {\"sum\": 64.0, \"count\": 1, \"min\": 64, \"max\": 64}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Number of Batches Since Last Reset\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #throughput_metric: host=algo-1, train throughput=42547.57005790608 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:38.239] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 163, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.2395632, \"EndTime\": 1653486638.2396295, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4179792823791504, \"count\": 1, \"min\": 0.4179792823791504, \"max\": 0.4179792823791504}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.2397537, \"EndTime\": 1653486638.239778, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42567447662353514, \"count\": 1, \"min\": 0.42567447662353514, \"max\": 0.42567447662353514}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.2398512, \"EndTime\": 1653486638.2398715, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42629653167724607, \"count\": 1, \"min\": 0.42629653167724607, \"max\": 0.42629653167724607}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.239957, \"EndTime\": 1653486638.2399774, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.415666446685791, \"count\": 1, \"min\": 0.415666446685791, \"max\": 0.415666446685791}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.2400386, \"EndTime\": 1653486638.2400544, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3258063430786133, \"count\": 1, \"min\": 0.3258063430786133, \"max\": 0.3258063430786133}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.2401066, \"EndTime\": 1653486638.2401226, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32696832275390625, \"count\": 1, \"min\": 0.32696832275390625, \"max\": 0.32696832275390625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.2401812, \"EndTime\": 1653486638.2401981, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32560688400268556, \"count\": 1, \"min\": 0.32560688400268556, \"max\": 0.32560688400268556}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.2402542, \"EndTime\": 1653486638.2402716, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3263659744262695, \"count\": 1, \"min\": 0.3263659744262695, \"max\": 0.3263659744262695}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #quality_metric: host=algo-1, epoch=6, train binary_classification_cross_entropy_objective <loss>=0.4179792823791504\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=binary_classification_cross_entropy_objective, value=0.32560688400268556\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Saving model for epoch: 6\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Saved checkpoint to \"/tmp/tmp6oxefqex/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #progress_metric: host=algo-1, completed 46.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.0758083, \"EndTime\": 1653486638.2522247, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 68200.0, \"count\": 1, \"min\": 68200, \"max\": 68200}, \"Total Batches Seen\": {\"sum\": 73.0, \"count\": 1, \"min\": 73, \"max\": 73}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Number of Batches Since Last Reset\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #throughput_metric: host=algo-1, train throughput=47572.510359857355 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:38.402] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 149, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.40266, \"EndTime\": 1653486638.4027784, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4090417022705078, \"count\": 1, \"min\": 0.4090417022705078, \"max\": 0.4090417022705078}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.4028986, \"EndTime\": 1653486638.402959, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4154868850708008, \"count\": 1, \"min\": 0.4154868850708008, \"max\": 0.4154868850708008}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.4030871, \"EndTime\": 1653486638.4031122, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4161751480102539, \"count\": 1, \"min\": 0.4161751480102539, \"max\": 0.4161751480102539}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.4032133, \"EndTime\": 1653486638.4032357, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.40639583587646483, \"count\": 1, \"min\": 0.40639583587646483, \"max\": 0.40639583587646483}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.4033346, \"EndTime\": 1653486638.4033556, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3253030014038086, \"count\": 1, \"min\": 0.3253030014038086, \"max\": 0.3253030014038086}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.4034464, \"EndTime\": 1653486638.403468, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32603279876708985, \"count\": 1, \"min\": 0.32603279876708985, \"max\": 0.32603279876708985}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.4035301, \"EndTime\": 1653486638.4035456, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32538510131835935, \"count\": 1, \"min\": 0.32538510131835935, \"max\": 0.32538510131835935}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.4036326, \"EndTime\": 1653486638.40365, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3256298942565918, \"count\": 1, \"min\": 0.3256298942565918, \"max\": 0.3256298942565918}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #quality_metric: host=algo-1, epoch=7, train binary_classification_cross_entropy_objective <loss>=0.4090417022705078\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=binary_classification_cross_entropy_objective, value=0.3253030014038086\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Saving model for epoch: 7\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Saved checkpoint to \"/tmp/tmpi_wrhwss/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #progress_metric: host=algo-1, completed 53.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.2525613, \"EndTime\": 1653486638.4309146, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 76600.0, \"count\": 1, \"min\": 76600, \"max\": 76600}, \"Total Batches Seen\": {\"sum\": 82.0, \"count\": 1, \"min\": 82, \"max\": 82}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Number of Batches Since Last Reset\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #throughput_metric: host=algo-1, train throughput=47046.71213925937 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:38.705] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 273, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.705565, \"EndTime\": 1653486638.7056613, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.40145791244506834, \"count\": 1, \"min\": 0.40145791244506834, \"max\": 0.40145791244506834}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.705788, \"EndTime\": 1653486638.7058084, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.40686261749267577, \"count\": 1, \"min\": 0.40686261749267577, \"max\": 0.40686261749267577}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.7058547, \"EndTime\": 1653486638.7058678, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4076704063415527, \"count\": 1, \"min\": 0.4076704063415527, \"max\": 0.4076704063415527}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.7059114, \"EndTime\": 1653486638.705923, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3985915603637695, \"count\": 1, \"min\": 0.3985915603637695, \"max\": 0.3985915603637695}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.7059958, \"EndTime\": 1653486638.7060158, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32585052490234373, \"count\": 1, \"min\": 0.32585052490234373, \"max\": 0.32585052490234373}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.7060623, \"EndTime\": 1653486638.7060745, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.326957088470459, \"count\": 1, \"min\": 0.326957088470459, \"max\": 0.326957088470459}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.7061481, \"EndTime\": 1653486638.706162, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32576750564575196, \"count\": 1, \"min\": 0.32576750564575196, \"max\": 0.32576750564575196}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.7062051, \"EndTime\": 1653486638.7062144, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32631181716918944, \"count\": 1, \"min\": 0.32631181716918944, \"max\": 0.32631181716918944}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #quality_metric: host=algo-1, epoch=8, train binary_classification_cross_entropy_objective <loss>=0.40145791244506834\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=binary_classification_cross_entropy_objective, value=0.32576750564575196\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Saving model for epoch: 8\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Saved checkpoint to \"/tmp/tmpmfxygwj4/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.4314344, \"EndTime\": 1653486638.720002, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 85000.0, \"count\": 1, \"min\": 85000, \"max\": 85000}, \"Total Batches Seen\": {\"sum\": 91.0, \"count\": 1, \"min\": 91, \"max\": 91}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Number of Batches Since Last Reset\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #throughput_metric: host=algo-1, train throughput=29088.94629813563 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:38.938] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 217, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.9384782, \"EndTime\": 1653486638.9385402, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3949451370239258, \"count\": 1, \"min\": 0.3949451370239258, \"max\": 0.3949451370239258}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.938681, \"EndTime\": 1653486638.938706, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3994659957885742, \"count\": 1, \"min\": 0.3994659957885742, \"max\": 0.3994659957885742}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.9387746, \"EndTime\": 1653486638.9387953, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.40042163848876955, \"count\": 1, \"min\": 0.40042163848876955, \"max\": 0.40042163848876955}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.9389045, \"EndTime\": 1653486638.9389641, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.39192185974121097, \"count\": 1, \"min\": 0.39192185974121097, \"max\": 0.39192185974121097}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.9390738, \"EndTime\": 1653486638.9390984, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32503357315063475, \"count\": 1, \"min\": 0.32503357315063475, \"max\": 0.32503357315063475}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.939229, \"EndTime\": 1653486638.939254, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32587944412231445, \"count\": 1, \"min\": 0.32587944412231445, \"max\": 0.32587944412231445}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.9393573, \"EndTime\": 1653486638.9393802, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3250988807678223, \"count\": 1, \"min\": 0.3250988807678223, \"max\": 0.3250988807678223}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.9395125, \"EndTime\": 1653486638.9395337, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32555301666259767, \"count\": 1, \"min\": 0.32555301666259767, \"max\": 0.32555301666259767}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #quality_metric: host=algo-1, epoch=9, train binary_classification_cross_entropy_objective <loss>=0.3949451370239258\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=binary_classification_cross_entropy_objective, value=0.32503357315063475\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Saving model for epoch: 9\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] Saved checkpoint to \"/tmp/tmpmx5lwmdx/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #progress_metric: host=algo-1, completed 66.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.7205274, \"EndTime\": 1653486638.9523513, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 93400.0, \"count\": 1, \"min\": 93400, \"max\": 93400}, \"Total Batches Seen\": {\"sum\": 100.0, \"count\": 1, \"min\": 100, \"max\": 100}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Number of Batches Since Last Reset\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:38 INFO 140002932959040] #throughput_metric: host=algo-1, train throughput=36207.25107880325 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:39.161] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 208, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486639.1617274, \"EndTime\": 1653486639.1617868, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3892374534606934, \"count\": 1, \"min\": 0.3892374534606934, \"max\": 0.3892374534606934}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486639.1618805, \"EndTime\": 1653486639.161899, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.39300196838378904, \"count\": 1, \"min\": 0.39300196838378904, \"max\": 0.39300196838378904}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486639.1619503, \"EndTime\": 1653486639.1619635, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3941137542724609, \"count\": 1, \"min\": 0.3941137542724609, \"max\": 0.3941137542724609}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486639.1620066, \"EndTime\": 1653486639.162019, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3860994033813477, \"count\": 1, \"min\": 0.3860994033813477, \"max\": 0.3860994033813477}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486639.1620662, \"EndTime\": 1653486639.1620793, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3254234275817871, \"count\": 1, \"min\": 0.3254234275817871, \"max\": 0.3254234275817871}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486639.162121, \"EndTime\": 1653486639.1621323, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3267551536560059, \"count\": 1, \"min\": 0.3267551536560059, \"max\": 0.3267551536560059}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486639.1621795, \"EndTime\": 1653486639.1621923, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32528665924072264, \"count\": 1, \"min\": 0.32528665924072264, \"max\": 0.32528665924072264}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486639.1622345, \"EndTime\": 1653486639.1622453, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.325878044128418, \"count\": 1, \"min\": 0.325878044128418, \"max\": 0.325878044128418}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #quality_metric: host=algo-1, epoch=10, train binary_classification_cross_entropy_objective <loss>=0.3892374534606934\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=binary_classification_cross_entropy_objective, value=0.32528665924072264\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] Saving model for epoch: 10\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] Saved checkpoint to \"/tmp/tmpiyisjwx3/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486638.9528725, \"EndTime\": 1653486639.1699831, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 101800.0, \"count\": 1, \"min\": 101800, \"max\": 101800}, \"Total Batches Seen\": {\"sum\": 109.0, \"count\": 1, \"min\": 109, \"max\": 109}, \"Max Records Seen Between Resets\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Max Batches Seen Between Resets\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 8400.0, \"count\": 1, \"min\": 8400, \"max\": 8400}, \"Number of Batches Since Last Reset\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}}}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #throughput_metric: host=algo-1, train throughput=38652.514618599904 records/second\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 WARNING 140002932959040] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 WARNING 140002932959040] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:39.177] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 6, \"num_examples\": 1, \"num_bytes\": 368000}\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:39.357] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 29, \"duration\": 174, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m[2022-05-25 13:50:39.450] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 31, \"duration\": 61, \"num_examples\": 9, \"num_bytes\": 3091200}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #train_score (algo-1) : ('binary_classification_cross_entropy_objective', 0.32029009682791576)\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #train_score (algo-1) : ('binary_classification_accuracy', 0.8523809523809524)\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #train_score (algo-1) : ('binary_f_1.000', 0.6593406593406593)\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #train_score (algo-1) : ('precision', 0.7194244604316546)\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #train_score (algo-1) : ('recall', 0.6085192697768763)\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #train_score (algo-1) : ('roc_auc_score', 0.9039565743684767)\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #train_score (algo-1) : ('binary_balanced_accuracy', 0.5)\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #train_score (algo-1) : ('binary_log_loss', 0.6938039854321656)\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #quality_metric: host=algo-1, train binary_classification_cross_entropy_objective <loss>=0.32029009682791576\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.8523809523809524\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.6593406593406593\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #quality_metric: host=algo-1, train precision <score>=0.7194244604316546\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #quality_metric: host=algo-1, train recall <score>=0.6085192697768763\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #quality_metric: host=algo-1, train roc_auc_score <score>=0.9039565743684767\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #quality_metric: host=algo-1, train binary_balanced_accuracy <score>=0.5\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] #quality_metric: host=algo-1, train binary_log_loss <score>=0.6938039854321656\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.1, \"wd\": 0.0001, \"l1\": 0.0, \"lr_scheduler_step\": 10, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 0.0001}\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] Saved checkpoint to \"/tmp/tmpxgtkom2h/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/25/2022 13:50:39 INFO 140002932959040] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1653486636.763923, \"EndTime\": 1653486639.4934351, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 202.21400260925293, \"count\": 1, \"min\": 202.21400260925293, \"max\": 202.21400260925293}, \"epochs\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"check_early_stopping.time\": {\"sum\": 10.56981086730957, \"count\": 11, \"min\": 0.244140625, \"max\": 1.7681121826171875}, \"update.time\": {\"sum\": 2090.1269912719727, \"count\": 11, \"min\": 120.53298950195312, \"max\": 279.94847297668457}, \"finalize.time\": {\"sum\": 317.5671100616455, \"count\": 1, \"min\": 317.5671100616455, \"max\": 317.5671100616455}, \"setuptime\": {\"sum\": 34.4696044921875, \"count\": 1, \"min\": 34.4696044921875, \"max\": 34.4696044921875}, \"totaltime\": {\"sum\": 3098.6313819885254, \"count\": 1, \"min\": 3098.6313819885254, \"max\": 3098.6313819885254}}}\u001b[0m\n",
      "\n",
      "2022-05-25 13:50:50 Uploading - Uploading generated training model\n",
      "2022-05-25 13:51:10 Completed - Training job completed\n",
      "Training seconds: 97\n",
      "Billable seconds: 97\n"
     ]
    }
   ],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/ecr-sa-east-1.html\n",
    "container = sagemaker.image_uris.retrieve(framework = 'linear-learner', region=boto3.Session().region_name)\n",
    "\n",
    "# https://aws.amazon.com/ec2/instance-types/\n",
    "# https://docs.aws.amazon.com/pt_br/AWSEC2/latest/UserGuide/instance-types.html\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-instance-types.html\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html\n",
    "# https://aws.amazon.com/pt/about-aws/whats-new/2019/08/amazon-sagemaker-launches-managed-spot-training-saving-machine-learning-training-costs/\n",
    "linear = sagemaker.estimator.Estimator(image_uri = container,\n",
    "                                       role = role,\n",
    "                                       instance_count = 1,\n",
    "                                       instance_type = 'ml.m4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = session,\n",
    "                                       use_stop_instances = True)\n",
    "\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/ll_hyperparameters.html\n",
    "linear.set_hyperparameters(feature_dim = 80,\n",
    "                           predictor_type = 'binary_classifier',\n",
    "                           num_models = 8)\n",
    "\n",
    "linear.fit({'train': s3_train_data_pca})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy, previsões e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "linear_classifier = linear.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "linear_classifier.serializer = CSVSerializer()\n",
    "linear_classifier.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 80)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = linear_classifier.predict(X_teste)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes = np.array([r['predicted_label'] for r in results['predictions']])\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste = np.array(y_teste).astype(int)\n",
    "y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8455555555555555"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2516,  189],\n",
       "       [ 367,  528]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_teste, previsoes)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      2705\n",
      "           1       0.74      0.59      0.66       895\n",
      "\n",
      "    accuracy                           0.85      3600\n",
      "   macro avg       0.80      0.76      0.78      3600\n",
      "weighted avg       0.84      0.85      0.84      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_teste, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:sa-east-1:782484402741:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
