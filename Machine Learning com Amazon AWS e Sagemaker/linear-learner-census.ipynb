{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento e exploração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>inative-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  final-weight    education  education-num  \\\n",
       "0       39          State-gov         77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc         83311    Bachelors             13   \n",
       "2       38            Private        215646      HS-grad              9   \n",
       "3       53            Private        234721         11th              7   \n",
       "4       28            Private        338409    Bachelors             13   \n",
       "...    ...                ...           ...          ...            ...   \n",
       "32556   27            Private        257302   Assoc-acdm             12   \n",
       "32557   40            Private        154374      HS-grad              9   \n",
       "32558   58            Private        151910      HS-grad              9   \n",
       "32559   22            Private        201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc        287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loos  hour-per-week inative-country  \\\n",
       "0         Male          2174             0             40   United-States   \n",
       "1         Male             0             0             13   United-States   \n",
       "2         Male             0             0             40   United-States   \n",
       "3         Male             0             0             40   United-States   \n",
       "4       Female             0             0             40            Cuba   \n",
       "...        ...           ...           ...            ...             ...   \n",
       "32556   Female             0             0             38   United-States   \n",
       "32557     Male             0             0             40   United-States   \n",
       "32558   Female             0             0             40   United-States   \n",
       "32559     Male             0             0             20   United-States   \n",
       "32560   Female         15024             0             40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_census = pd.read_csv('census.csv')\n",
    "base_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  final-weight  education-num  capital-gain  capital-loos  \\\n",
       "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
       "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hour-per-week  \n",
       "count   32561.000000  \n",
       "mean       40.437456  \n",
       "std        12.347429  \n",
       "min         1.000000  \n",
       "25%        40.000000  \n",
       "50%        40.000000  \n",
       "75%        45.000000  \n",
       "max        99.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_census.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "workclass          0\n",
       "final-weight       0\n",
       "education          0\n",
       "education-num      0\n",
       "marital-status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "sex                0\n",
       "capital-gain       0\n",
       "capital-loos       0\n",
       "hour-per-week      0\n",
       "inative-country    0\n",
       "income             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_census.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([' <=50K', ' >50K'], dtype=object), array([24720,  7841]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(base_census['income'], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = base_census['income']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x = base_census['age']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x = base_census['education-num']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x = base_census['hour-per-week']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'final-weight', 'education', 'education-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital-gain', 'capital-loos', 'hour-per-week', 'inative-country',\n",
       "       'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = []\n",
    "colunas.append('income')\n",
    "for i in range(len(base_census.columns[:-1])):\n",
    "    #print(i)\n",
    "    #print(base_census.columns[i])\n",
    "    colunas.append(base_census.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['income',\n",
       " 'age',\n",
       " 'workclass',\n",
       " 'final-weight',\n",
       " 'education',\n",
       " 'education-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital-gain',\n",
       " 'capital-loos',\n",
       " 'hour-per-week',\n",
       " 'inative-country']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>inative-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       income  age          workclass  final-weight    education  \\\n",
       "0       <=50K   39          State-gov         77516    Bachelors   \n",
       "1       <=50K   50   Self-emp-not-inc         83311    Bachelors   \n",
       "2       <=50K   38            Private        215646      HS-grad   \n",
       "3       <=50K   53            Private        234721         11th   \n",
       "4       <=50K   28            Private        338409    Bachelors   \n",
       "...       ...  ...                ...           ...          ...   \n",
       "32556   <=50K   27            Private        257302   Assoc-acdm   \n",
       "32557    >50K   40            Private        154374      HS-grad   \n",
       "32558   <=50K   58            Private        151910      HS-grad   \n",
       "32559   <=50K   22            Private        201490      HS-grad   \n",
       "32560    >50K   52       Self-emp-inc        287927      HS-grad   \n",
       "\n",
       "       education-num       marital-status          occupation    relationship  \\\n",
       "0                 13        Never-married        Adm-clerical   Not-in-family   \n",
       "1                 13   Married-civ-spouse     Exec-managerial         Husband   \n",
       "2                  9             Divorced   Handlers-cleaners   Not-in-family   \n",
       "3                  7   Married-civ-spouse   Handlers-cleaners         Husband   \n",
       "4                 13   Married-civ-spouse      Prof-specialty            Wife   \n",
       "...              ...                  ...                 ...             ...   \n",
       "32556             12   Married-civ-spouse        Tech-support            Wife   \n",
       "32557              9   Married-civ-spouse   Machine-op-inspct         Husband   \n",
       "32558              9              Widowed        Adm-clerical       Unmarried   \n",
       "32559              9        Never-married        Adm-clerical       Own-child   \n",
       "32560              9   Married-civ-spouse     Exec-managerial            Wife   \n",
       "\n",
       "         race      sex  capital-gain  capital-loos  hour-per-week  \\\n",
       "0       White     Male          2174             0             40   \n",
       "1       White     Male             0             0             13   \n",
       "2       White     Male             0             0             40   \n",
       "3       Black     Male             0             0             40   \n",
       "4       Black   Female             0             0             40   \n",
       "...       ...      ...           ...           ...            ...   \n",
       "32556   White   Female             0             0             38   \n",
       "32557   White     Male             0             0             40   \n",
       "32558   White   Female             0             0             40   \n",
       "32559   White     Male             0             0             20   \n",
       "32560   White   Female         15024             0             40   \n",
       "\n",
       "      inative-country  \n",
       "0       United-States  \n",
       "1       United-States  \n",
       "2       United-States  \n",
       "3       United-States  \n",
       "4                Cuba  \n",
       "...               ...  \n",
       "32556   United-States  \n",
       "32557   United-States  \n",
       "32558   United-States  \n",
       "32559   United-States  \n",
       "32560   United-States  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_census = base_census[colunas]\n",
    "base_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Husband', ' Not-in-family', ' Other-relative', ' Own-child',\n",
       "       ' Unmarried', ' Wife'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(base_census['relationship'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0, 1, 2, 3, 4, 5\n",
    "# OneHotEncoder - variáveis dummies\n",
    "# 1 0 0 0 0 0\n",
    "# 0 1 0 0 0 0\n",
    "# 0 0 1 0 0 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Husband</th>\n",
       "      <th>Not-in-family</th>\n",
       "      <th>Other-relative</th>\n",
       "      <th>Own-child</th>\n",
       "      <th>Unmarried</th>\n",
       "      <th>Wife</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Husband   Not-in-family   Other-relative   Own-child   Unmarried  \\\n",
       "0             0               1                0           0           0   \n",
       "1             1               0                0           0           0   \n",
       "2             0               1                0           0           0   \n",
       "3             1               0                0           0           0   \n",
       "4             0               0                0           0           0   \n",
       "...         ...             ...              ...         ...         ...   \n",
       "32556         0               0                0           0           0   \n",
       "32557         1               0                0           0           0   \n",
       "32558         0               0                0           0           1   \n",
       "32559         0               0                0           1           0   \n",
       "32560         0               0                0           0           0   \n",
       "\n",
       "        Wife  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "...      ...  \n",
       "32556      1  \n",
       "32557      0  \n",
       "32558      0  \n",
       "32559      0  \n",
       "32560      1  \n",
       "\n",
       "[32561 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(base_census['relationship'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>inative-country_ Portugal</th>\n",
       "      <th>inative-country_ Puerto-Rico</th>\n",
       "      <th>inative-country_ Scotland</th>\n",
       "      <th>inative-country_ South</th>\n",
       "      <th>inative-country_ Taiwan</th>\n",
       "      <th>inative-country_ Thailand</th>\n",
       "      <th>inative-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>inative-country_ United-States</th>\n",
       "      <th>inative-country_ Vietnam</th>\n",
       "      <th>inative-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>27</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>40</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>58</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>22</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>52</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       income  age  final-weight  education-num  capital-gain  capital-loos  \\\n",
       "0       <=50K   39         77516             13          2174             0   \n",
       "1       <=50K   50         83311             13             0             0   \n",
       "2       <=50K   38        215646              9             0             0   \n",
       "3       <=50K   53        234721              7             0             0   \n",
       "4       <=50K   28        338409             13             0             0   \n",
       "...       ...  ...           ...            ...           ...           ...   \n",
       "32556   <=50K   27        257302             12             0             0   \n",
       "32557    >50K   40        154374              9             0             0   \n",
       "32558   <=50K   58        151910              9             0             0   \n",
       "32559   <=50K   22        201490              9             0             0   \n",
       "32560    >50K   52        287927              9         15024             0   \n",
       "\n",
       "       hour-per-week  workclass_ ?  workclass_ Federal-gov  \\\n",
       "0                 40             0                       0   \n",
       "1                 13             0                       0   \n",
       "2                 40             0                       0   \n",
       "3                 40             0                       0   \n",
       "4                 40             0                       0   \n",
       "...              ...           ...                     ...   \n",
       "32556             38             0                       0   \n",
       "32557             40             0                       0   \n",
       "32558             40             0                       0   \n",
       "32559             20             0                       0   \n",
       "32560             40             0                       0   \n",
       "\n",
       "       workclass_ Local-gov  ...  inative-country_ Portugal  \\\n",
       "0                         0  ...                          0   \n",
       "1                         0  ...                          0   \n",
       "2                         0  ...                          0   \n",
       "3                         0  ...                          0   \n",
       "4                         0  ...                          0   \n",
       "...                     ...  ...                        ...   \n",
       "32556                     0  ...                          0   \n",
       "32557                     0  ...                          0   \n",
       "32558                     0  ...                          0   \n",
       "32559                     0  ...                          0   \n",
       "32560                     0  ...                          0   \n",
       "\n",
       "       inative-country_ Puerto-Rico  inative-country_ Scotland  \\\n",
       "0                                 0                          0   \n",
       "1                                 0                          0   \n",
       "2                                 0                          0   \n",
       "3                                 0                          0   \n",
       "4                                 0                          0   \n",
       "...                             ...                        ...   \n",
       "32556                             0                          0   \n",
       "32557                             0                          0   \n",
       "32558                             0                          0   \n",
       "32559                             0                          0   \n",
       "32560                             0                          0   \n",
       "\n",
       "       inative-country_ South  inative-country_ Taiwan  \\\n",
       "0                           0                        0   \n",
       "1                           0                        0   \n",
       "2                           0                        0   \n",
       "3                           0                        0   \n",
       "4                           0                        0   \n",
       "...                       ...                      ...   \n",
       "32556                       0                        0   \n",
       "32557                       0                        0   \n",
       "32558                       0                        0   \n",
       "32559                       0                        0   \n",
       "32560                       0                        0   \n",
       "\n",
       "       inative-country_ Thailand  inative-country_ Trinadad&Tobago  \\\n",
       "0                              0                                 0   \n",
       "1                              0                                 0   \n",
       "2                              0                                 0   \n",
       "3                              0                                 0   \n",
       "4                              0                                 0   \n",
       "...                          ...                               ...   \n",
       "32556                          0                                 0   \n",
       "32557                          0                                 0   \n",
       "32558                          0                                 0   \n",
       "32559                          0                                 0   \n",
       "32560                          0                                 0   \n",
       "\n",
       "       inative-country_ United-States  inative-country_ Vietnam  \\\n",
       "0                                   1                         0   \n",
       "1                                   1                         0   \n",
       "2                                   1                         0   \n",
       "3                                   1                         0   \n",
       "4                                   0                         0   \n",
       "...                               ...                       ...   \n",
       "32556                               1                         0   \n",
       "32557                               1                         0   \n",
       "32558                               1                         0   \n",
       "32559                               1                         0   \n",
       "32560                               1                         0   \n",
       "\n",
       "       inative-country_ Yugoslavia  \n",
       "0                                0  \n",
       "1                                0  \n",
       "2                                0  \n",
       "3                                0  \n",
       "4                                0  \n",
       "...                            ...  \n",
       "32556                            0  \n",
       "32557                            0  \n",
       "32558                            0  \n",
       "32559                            0  \n",
       "32560                            0  \n",
       "\n",
       "[32561 rows x 109 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_census = pd.get_dummies(base_census, prefix = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'inative-country'],\n",
    "                             columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'inative-country'])\n",
    "base_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['income', 'age', 'final-weight', 'education-num', 'capital-gain',\n",
       "       'capital-loos', 'hour-per-week', 'workclass_ ?',\n",
       "       'workclass_ Federal-gov', 'workclass_ Local-gov',\n",
       "       ...\n",
       "       'inative-country_ Portugal', 'inative-country_ Puerto-Rico',\n",
       "       'inative-country_ Scotland', 'inative-country_ South',\n",
       "       'inative-country_ Taiwan', 'inative-country_ Thailand',\n",
       "       'inative-country_ Trinadad&Tobago', 'inative-country_ United-States',\n",
       "       'inative-country_ Vietnam', 'inative-country_ Yugoslavia'],\n",
       "      dtype='object', length=109)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.90000e+01, 7.75160e+04, 1.30000e+01, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [5.00000e+01, 8.33110e+04, 1.30000e+01, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [3.80000e+01, 2.15646e+05, 9.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       ...,\n",
       "       [5.80000e+01, 1.51910e+05, 9.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [2.20000e+01, 2.01490e+05, 9.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [5.20000e+01, 2.87927e+05, 9.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = base_census.iloc[:, 1:len(base_census)].values\n",
    "X = np.array(X).astype('float32')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32561, 108), numpy.ndarray)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9000e+01, 7.7516e+04, 1.3000e+01, 2.1740e+03, 0.0000e+00,\n",
       "       4.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 0.0000e+00], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' <=50K', ..., ' <=50K', ' <=50K', ' >50K'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = base_census.iloc[:, 0].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = []\n",
    "for i in y:\n",
    "    #print(i)\n",
    "    if i == ' >50K':\n",
    "        y_1.append(1.0)\n",
    "    else:\n",
    "        y_1.append(0.0)\n",
    "print(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y_1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22792, 108), (9769, 108))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treinamento.shape, X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22792,), (9769,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treinamento.shape, y_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações do SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import Session\n",
    "import sagemaker.amazon.common as smac\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localização da base de dados:  s3://cursoawssagemaker/datasets/census/train/census-train-data\n",
      "Modelo final será salvo em:  s3://cursoawssagemaker/modelos/census/linear-learner/output\n"
     ]
    }
   ],
   "source": [
    "session = sagemaker.Session()\n",
    "bucket = 'cursoawssagemaker'\n",
    "subpasta_modelo = 'modelos/census/linear-learner'\n",
    "subpasta_dataset = 'datasets/census'\n",
    "key = 'census-train-data'\n",
    "role = sagemaker.get_execution_role()\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, subpasta_dataset, key)\n",
    "output_location = 's3://{}/{}/output'.format(bucket, subpasta_modelo)\n",
    "print('Localização da base de dados: ', s3_train_data)\n",
    "print('Modelo final será salvo em: ', output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buffer, X_treinamento, y_treinamento)\n",
    "buffer.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(subpasta_dataset, 'train', key)).upload_fileobj(buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação e treinamento do Linear Lerner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/ecr-sa-east-1.html\n",
    "container = sagemaker.image_uris.retrieve(framework = 'linear-learner', region=boto3.Session().region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://aws.amazon.com/ec2/instance-types/\n",
    "# https://docs.aws.amazon.com/pt_br/AWSEC2/latest/UserGuide/instance-types.html\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-instance-types.html\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html\n",
    "# https://aws.amazon.com/pt/about-aws/whats-new/2019/08/amazon-sagemaker-launches-managed-spot-training-saving-machine-learning-training-costs/\n",
    "linear = sagemaker.estimator.Estimator(image_uri = container,\n",
    "                                       role = role,\n",
    "                                       instance_count = 1,\n",
    "                                       instance_type = 'ml.m4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = session,\n",
    "                                       use_stop_instances = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/ll_hyperparameters.html\n",
    "linear.set_hyperparameters(feature_dim = 108,\n",
    "                           predictor_type = 'binary_classifier',\n",
    "                           num_models = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-17 14:39:31 Starting - Starting the training job...\n",
      "2022-05-17 14:39:59 Starting - Preparing the instances for trainingProfilerReport-1652798371: InProgress\n",
      "............\n",
      "2022-05-17 14:41:57 Downloading - Downloading input data...\n",
      "2022-05-17 14:42:17 Training - Downloading the training image.....\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:16 INFO 140480837568320] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:16 INFO 140480837568320] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '108', 'num_models': '8', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:16 INFO 140480837568320] Final configuration: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': '108', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': '8', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:16 WARNING 140480837568320] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:16 INFO 140480837568320] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:16 INFO 140480837568320] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:16.891] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 36, \"num_examples\": 1, \"num_bytes\": 480000}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:16 INFO 140480837568320] Create Store: local\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:17.015] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 123, \"num_examples\": 11, \"num_bytes\": 5280000}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7fc3de738650>\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Scaling model computed with parameters:\n",
      " {'stdev_label': None, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[1.3601592e+01 1.0607855e+05 2.5679152e+00 8.0187715e+03 3.9976019e+02\n",
      " 1.2412492e+01 2.3236300e-01 1.6600947e-01 2.4970682e-01 1.3482772e-02\n",
      " 4.6151519e-01 1.7744365e-01 2.7129313e-01 2.0017347e-01 2.5218222e-02\n",
      " 1.5750118e-01 1.7672352e-01 1.1209501e-01 6.9892719e-02 1.0127307e-01\n",
      " 1.4308004e-01 1.2441837e-01 1.6932964e-01 2.0690459e-01 3.7126255e-01\n",
      " 1.0969695e-01 4.7001514e-01 2.2637613e-01 4.3651417e-02 1.3262111e-01\n",
      " 4.1595545e-01 3.4065235e-01 2.5218222e-02 4.9853998e-01 1.0682770e-01\n",
      " 4.7083357e-01 1.7380884e-01 1.6806139e-01 2.3270908e-01 3.2260814e-01\n",
      " 1.3482771e-02 3.3519995e-01 3.3040944e-01 1.7282484e-01 2.0448765e-01\n",
      " 2.3218971e-01 2.9999998e-01 5.6317795e-02 3.2958156e-01 1.4459333e-01\n",
      " 3.1614777e-01 1.6678227e-01 2.1605787e-01 4.9122316e-01 4.3306518e-01\n",
      " 1.7405385e-01 3.6601487e-01 3.0584931e-01 2.1395834e-01 9.6773736e-02\n",
      " 1.7551577e-01 2.9346594e-01 9.3966573e-02 3.5246709e-01 4.6975061e-01\n",
      " 4.6975061e-01 1.3684461e-01 2.6958188e-02 6.3118935e-02 4.5678630e-02\n",
      " 4.6658956e-02 5.3011697e-02 4.4676621e-02 3.6902260e-02 5.1277801e-02\n",
      " 4.2601362e-02 3.1606961e-02 6.0192529e-02 2.3348598e-02 3.9281882e-02\n",
      " 4.1524559e-02 1.0000000e+00 1.6512204e-02 2.5218224e-02 2.5218222e-02\n",
      " 5.6317803e-02 3.5652593e-02 2.1315226e-02 4.7618929e-02 5.0388247e-02\n",
      " 4.5678630e-02 1.9065782e-02 1.3588251e-01 3.0137427e-02 2.1315226e-02\n",
      " 3.3010893e-02 7.7806234e-02 3.6902264e-02 3.3010885e-02 6.9245696e-02\n",
      " 1.6512204e-02 4.7618914e-02 4.0418886e-02 3.1606965e-02 2.6958186e-02\n",
      " 3.0514255e-01 4.2601369e-02 2.5218224e-02]\u001b[0m\n",
      "\u001b[34m<NDArray 108 @cpu(0)>, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[3.85268250e+01 1.89367375e+05 1.00919094e+01 1.17178320e+03\n",
      " 8.41724625e+01 4.03910980e+01 5.72727285e-02 2.83636376e-02\n",
      " 6.68181777e-02 1.81818192e-04 6.92363739e-01 3.25454548e-02\n",
      " 7.99999982e-02 4.18181829e-02 6.36363635e-04 2.54545491e-02\n",
      " 3.22727263e-02 1.27272746e-02 4.90909163e-03 1.03636375e-02\n",
      " 2.09090915e-02 1.57272723e-02 2.95454562e-02 4.48181853e-02\n",
      " 1.65090933e-01 1.21818194e-02 3.29454541e-01 5.41818254e-02\n",
      " 1.90909114e-03 1.79090928e-02 2.22545475e-01 1.34000018e-01\n",
      " 6.36363635e-04 4.61818248e-01 1.15454551e-02 3.31727326e-01\n",
      " 3.11818179e-02 2.90909149e-02 5.74545488e-02 1.18000001e-01\n",
      " 1.81818163e-04 1.29000008e-01 1.24727286e-01 3.08181867e-02\n",
      " 4.37272713e-02 5.71818203e-02 1.00000009e-01 3.18181864e-03\n",
      " 1.24000005e-01 2.13636383e-02 1.12636372e-01 2.86363643e-02\n",
      " 4.90909182e-02 4.06727314e-01 2.50090897e-01 3.12727317e-02\n",
      " 1.59363657e-01 1.04454547e-01 4.80909087e-02 9.45454743e-03\n",
      " 3.18181850e-02 9.51818228e-02 8.90909135e-03 8.54636431e-01\n",
      " 3.28727275e-01 6.71272874e-01 1.90909095e-02 7.27272767e-04\n",
      " 4.00000019e-03 2.09090929e-03 2.18181848e-03 2.81818188e-03\n",
      " 2.00000033e-03 1.36363646e-03 2.63636396e-03 1.81818195e-03\n",
      " 1.00000005e-03 3.63636366e-03 5.45454561e-04 1.54545461e-03\n",
      " 1.72727287e-03 0.00000000e+00 2.72727280e-04 6.36363693e-04\n",
      " 6.36363693e-04 3.18181817e-03 1.27272750e-03 4.54545487e-04\n",
      " 2.27272743e-03 2.54545454e-03 2.09090905e-03 3.63636354e-04\n",
      " 1.88181847e-02 9.09091032e-04 4.54545487e-04 1.09090912e-03\n",
      " 6.09090971e-03 1.36363634e-03 1.09090924e-03 4.81818197e-03\n",
      " 2.72727251e-04 2.27272767e-03 1.63636345e-03 9.99999931e-04\n",
      " 7.27272767e-04 8.96090984e-01 1.81818206e-03 6.36363635e-04]\u001b[0m\n",
      "\u001b[34m<NDArray 108 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.0785506, \"EndTime\": 1652798597.078617, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12000.0, \"count\": 1, \"min\": 12000, \"max\": 12000}, \"Total Batches Seen\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Max Records Seen Between Resets\": {\"sum\": 11000.0, \"count\": 1, \"min\": 11000, \"max\": 11000}, \"Max Batches Seen Between Resets\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:17.351] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 272, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.3518717, \"EndTime\": 1652798597.3519454, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5339542111483487, \"count\": 1, \"min\": 0.5339542111483487, \"max\": 0.5339542111483487}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.3520813, \"EndTime\": 1652798597.3521051, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.505571269642223, \"count\": 1, \"min\": 0.505571269642223, \"max\": 0.505571269642223}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.352169, \"EndTime\": 1652798597.3521893, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5159106375954368, \"count\": 1, \"min\": 0.5159106375954368, \"max\": 0.5159106375954368}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.3522475, \"EndTime\": 1652798597.3522654, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5256724617697975, \"count\": 1, \"min\": 0.5256724617697975, \"max\": 0.5256724617697975}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.352321, \"EndTime\": 1652798597.352338, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42479263028231534, \"count\": 1, \"min\": 0.42479263028231534, \"max\": 0.42479263028231534}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.3523939, \"EndTime\": 1652798597.3524106, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42984462252530187, \"count\": 1, \"min\": 0.42984462252530187, \"max\": 0.42984462252530187}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.352463, \"EndTime\": 1652798597.3524814, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42672873757102275, \"count\": 1, \"min\": 0.42672873757102275, \"max\": 0.42672873757102275}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.3525336, \"EndTime\": 1652798597.3525493, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4287576668479226, \"count\": 1, \"min\": 0.4287576668479226, \"max\": 0.4287576668479226}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy_objective <loss>=0.5339542111483487\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=binary_classification_cross_entropy_objective, value=0.42479263028231534\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Saved checkpoint to \"/tmp/tmpdcs4yji9/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #progress_metric: host=algo-1, completed 6.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.0790687, \"EndTime\": 1652798597.3677714, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 34792.0, \"count\": 1, \"min\": 34792, \"max\": 34792}, \"Total Batches Seen\": {\"sum\": 35.0, \"count\": 1, \"min\": 35, \"max\": 35}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=78903.90362814131 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:17.620] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 251, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.6209018, \"EndTime\": 1652798597.621056, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3793128107244318, \"count\": 1, \"min\": 0.3793128107244318, \"max\": 0.3793128107244318}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.6211882, \"EndTime\": 1652798597.621238, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.37059965515136717, \"count\": 1, \"min\": 0.37059965515136717, \"max\": 0.37059965515136717}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.6213446, \"EndTime\": 1652798597.6214097, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3711096024946733, \"count\": 1, \"min\": 0.3711096024946733, \"max\": 0.3711096024946733}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.6215565, \"EndTime\": 1652798597.6215794, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.37822110817649146, \"count\": 1, \"min\": 0.37822110817649146, \"max\": 0.37822110817649146}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.621676, \"EndTime\": 1652798597.6217332, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3559637478915128, \"count\": 1, \"min\": 0.3559637478915128, \"max\": 0.3559637478915128}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.6218693, \"EndTime\": 1652798597.6218915, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.35842683826793326, \"count\": 1, \"min\": 0.35842683826793326, \"max\": 0.35842683826793326}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.622023, \"EndTime\": 1652798597.6220443, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3544693173495206, \"count\": 1, \"min\": 0.3544693173495206, \"max\": 0.3544693173495206}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.6221843, \"EndTime\": 1652798597.6222367, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3558672402121804, \"count\": 1, \"min\": 0.3558672402121804, \"max\": 0.3558672402121804}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy_objective <loss>=0.3793128107244318\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=binary_classification_cross_entropy_objective, value=0.3544693173495206\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Saved checkpoint to \"/tmp/tmp0lt_2hv4/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #progress_metric: host=algo-1, completed 13.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.3687236, \"EndTime\": 1652798597.633108, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 57584.0, \"count\": 1, \"min\": 57584, \"max\": 57584}, \"Total Batches Seen\": {\"sum\": 58.0, \"count\": 1, \"min\": 58, \"max\": 58}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=86146.79070806908 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:17.959] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 325, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.9595637, \"EndTime\": 1652798597.9596286, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.35168800631436437, \"count\": 1, \"min\": 0.35168800631436437, \"max\": 0.35168800631436437}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.9597757, \"EndTime\": 1652798597.9597976, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3480580985329368, \"count\": 1, \"min\": 0.3480580985329368, \"max\": 0.3480580985329368}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.95986, \"EndTime\": 1652798597.95988, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34670319851962, \"count\": 1, \"min\": 0.34670319851962, \"max\": 0.34670319851962}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.9599469, \"EndTime\": 1652798597.9599643, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.35150217229669745, \"count\": 1, \"min\": 0.35150217229669745, \"max\": 0.35150217229669745}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.9600217, \"EndTime\": 1652798597.9600394, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34356449057839133, \"count\": 1, \"min\": 0.34356449057839133, \"max\": 0.34356449057839133}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.9600968, \"EndTime\": 1652798597.9601145, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34587859552556816, \"count\": 1, \"min\": 0.34587859552556816, \"max\": 0.34587859552556816}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.9601703, \"EndTime\": 1652798597.9601867, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3432105879350142, \"count\": 1, \"min\": 0.3432105879350142, \"max\": 0.3432105879350142}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.9602447, \"EndTime\": 1652798597.9602606, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34694285999644886, \"count\": 1, \"min\": 0.34694285999644886, \"max\": 0.34694285999644886}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy_objective <loss>=0.35168800631436437\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=binary_classification_cross_entropy_objective, value=0.3432105879350142\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] Saved checkpoint to \"/tmp/tmpn_pg4ghh/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.634156, \"EndTime\": 1652798597.9697597, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 80376.0, \"count\": 1, \"min\": 80376, \"max\": 80376}, \"Total Batches Seen\": {\"sum\": 81.0, \"count\": 1, \"min\": 81, \"max\": 81}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:17 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=67883.869524803 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:18.338] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 367, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.3384593, \"EndTime\": 1652798598.3385267, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3421622647372159, \"count\": 1, \"min\": 0.3421622647372159, \"max\": 0.3421622647372159}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.3388386, \"EndTime\": 1652798598.3388658, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3407387029474432, \"count\": 1, \"min\": 0.3407387029474432, \"max\": 0.3407387029474432}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.3389683, \"EndTime\": 1652798598.3389895, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33889214810458096, \"count\": 1, \"min\": 0.33889214810458096, \"max\": 0.33889214810458096}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.339112, \"EndTime\": 1652798598.3391283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.342393105246804, \"count\": 1, \"min\": 0.342393105246804, \"max\": 0.342393105246804}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.3391836, \"EndTime\": 1652798598.3392017, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34244303755326705, \"count\": 1, \"min\": 0.34244303755326705, \"max\": 0.34244303755326705}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.3392603, \"EndTime\": 1652798598.3392775, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34480622308904474, \"count\": 1, \"min\": 0.34480622308904474, \"max\": 0.34480622308904474}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.3393326, \"EndTime\": 1652798598.33935, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3415060410933061, \"count\": 1, \"min\": 0.3415060410933061, \"max\": 0.3415060410933061}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.3394043, \"EndTime\": 1652798598.3394206, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.343430776422674, \"count\": 1, \"min\": 0.343430776422674, \"max\": 0.343430776422674}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy_objective <loss>=0.3421622647372159\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=binary_classification_cross_entropy_objective, value=0.33889214810458096\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] Saved checkpoint to \"/tmp/tmpypy_xkok/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] #progress_metric: host=algo-1, completed 26.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798597.9707289, \"EndTime\": 1652798598.3492718, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 103168.0, \"count\": 1, \"min\": 103168, \"max\": 103168}, \"Total Batches Seen\": {\"sum\": 104.0, \"count\": 1, \"min\": 104, \"max\": 104}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=60187.15145165779 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:18.763] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 412, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.763372, \"EndTime\": 1652798598.7634332, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3373507315895774, \"count\": 1, \"min\": 0.3373507315895774, \"max\": 0.3373507315895774}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.7635329, \"EndTime\": 1652798598.7635477, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33699022882634944, \"count\": 1, \"min\": 0.33699022882634944, \"max\": 0.33699022882634944}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.763633, \"EndTime\": 1652798598.763652, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.335022817438299, \"count\": 1, \"min\": 0.335022817438299, \"max\": 0.335022817438299}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.7637165, \"EndTime\": 1652798598.7637353, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3378738278475675, \"count\": 1, \"min\": 0.3378738278475675, \"max\": 0.3378738278475675}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.7637904, \"EndTime\": 1652798598.7638075, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3390813307328658, \"count\": 1, \"min\": 0.3390813307328658, \"max\": 0.3390813307328658}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.7638645, \"EndTime\": 1652798598.7638803, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3423691101074219, \"count\": 1, \"min\": 0.3423691101074219, \"max\": 0.3423691101074219}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.763936, \"EndTime\": 1652798598.7639525, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33995772205699576, \"count\": 1, \"min\": 0.33995772205699576, \"max\": 0.33995772205699576}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.7640076, \"EndTime\": 1652798598.764025, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34313213833895595, \"count\": 1, \"min\": 0.34313213833895595, \"max\": 0.34313213833895595}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy_objective <loss>=0.3373507315895774\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=binary_classification_cross_entropy_objective, value=0.335022817438299\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] Saved checkpoint to \"/tmp/tmprcxzt8yb/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] #progress_metric: host=algo-1, completed 33.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.3502235, \"EndTime\": 1652798598.77651, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 125960.0, \"count\": 1, \"min\": 125960, \"max\": 125960}, \"Total Batches Seen\": {\"sum\": 127.0, \"count\": 1, \"min\": 127, \"max\": 127}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:18 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=53433.043242629916 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:19.161] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 381, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.1616533, \"EndTime\": 1652798599.1617203, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3343948641690341, \"count\": 1, \"min\": 0.3343948641690341, \"max\": 0.3343948641690341}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.1618261, \"EndTime\": 1652798599.161848, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3346127624511719, \"count\": 1, \"min\": 0.3346127624511719, \"max\": 0.3346127624511719}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.1619127, \"EndTime\": 1652798599.1619327, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3326120175448331, \"count\": 1, \"min\": 0.3326120175448331, \"max\": 0.3326120175448331}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.161992, \"EndTime\": 1652798599.1620114, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33510351423783735, \"count\": 1, \"min\": 0.33510351423783735, \"max\": 0.33510351423783735}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.1620684, \"EndTime\": 1652798599.1620865, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33936849836869676, \"count\": 1, \"min\": 0.33936849836869676, \"max\": 0.33936849836869676}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.1621401, \"EndTime\": 1652798599.1621568, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34152237770774146, \"count\": 1, \"min\": 0.34152237770774146, \"max\": 0.34152237770774146}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.1622117, \"EndTime\": 1652798599.1622293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3379544081254439, \"count\": 1, \"min\": 0.3379544081254439, \"max\": 0.3379544081254439}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.1622846, \"EndTime\": 1652798599.1623025, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3421613838889382, \"count\": 1, \"min\": 0.3421613838889382, \"max\": 0.3421613838889382}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #quality_metric: host=algo-1, epoch=5, train binary_classification_cross_entropy_objective <loss>=0.3343948641690341\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=binary_classification_cross_entropy_objective, value=0.3326120175448331\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] Saving model for epoch: 5\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] Saved checkpoint to \"/tmp/tmp3fvj6fz3/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798598.7798984, \"EndTime\": 1652798599.184188, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 148752.0, \"count\": 1, \"min\": 148752, \"max\": 148752}, \"Total Batches Seen\": {\"sum\": 150.0, \"count\": 1, \"min\": 150, \"max\": 150}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=56352.8479355904 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:19.545] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 15, \"duration\": 360, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.5462105, \"EndTime\": 1652798599.5462766, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33230338911576707, \"count\": 1, \"min\": 0.33230338911576707, \"max\": 0.33230338911576707}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.5466778, \"EndTime\": 1652798599.5467358, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33286027804288, \"count\": 1, \"min\": 0.33286027804288, \"max\": 0.33286027804288}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.5471148, \"EndTime\": 1652798599.547144, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33086456021395594, \"count\": 1, \"min\": 0.33086456021395594, \"max\": 0.33086456021395594}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.5474865, \"EndTime\": 1652798599.5475774, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33312633306329903, \"count\": 1, \"min\": 0.33312633306329903, \"max\": 0.33312633306329903}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.547923, \"EndTime\": 1652798599.5479813, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33906985889781605, \"count\": 1, \"min\": 0.33906985889781605, \"max\": 0.33906985889781605}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.5483198, \"EndTime\": 1652798599.5483763, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34247803011807526, \"count\": 1, \"min\": 0.34247803011807526, \"max\": 0.34247803011807526}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.54872, \"EndTime\": 1652798599.548874, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3394644206653942, \"count\": 1, \"min\": 0.3394644206653942, \"max\": 0.3394644206653942}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.5489612, \"EndTime\": 1652798599.5489836, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3434546883322976, \"count\": 1, \"min\": 0.3434546883322976, \"max\": 0.3434546883322976}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #quality_metric: host=algo-1, epoch=6, train binary_classification_cross_entropy_objective <loss>=0.33230338911576707\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=binary_classification_cross_entropy_objective, value=0.33086456021395594\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] Saving model for epoch: 6\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] Saved checkpoint to \"/tmp/tmpkrr1m7xn/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #progress_metric: host=algo-1, completed 46.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.1850555, \"EndTime\": 1652798599.5603278, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 171544.0, \"count\": 1, \"min\": 171544, \"max\": 171544}, \"Total Batches Seen\": {\"sum\": 173.0, \"count\": 1, \"min\": 173, \"max\": 173}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=60711.5809379132 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:19.956] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 395, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.9568079, \"EndTime\": 1652798599.9571378, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3307119404185902, \"count\": 1, \"min\": 0.3307119404185902, \"max\": 0.3307119404185902}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.9572787, \"EndTime\": 1652798599.9573383, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33146796902743253, \"count\": 1, \"min\": 0.33146796902743253, \"max\": 0.33146796902743253}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.9575517, \"EndTime\": 1652798599.9577868, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32950421836159444, \"count\": 1, \"min\": 0.32950421836159444, \"max\": 0.32950421836159444}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.9578965, \"EndTime\": 1652798599.9579184, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33160048744895243, \"count\": 1, \"min\": 0.33160048744895243, \"max\": 0.33160048744895243}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.9584322, \"EndTime\": 1652798599.9584618, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3382545471191406, \"count\": 1, \"min\": 0.3382545471191406, \"max\": 0.3382545471191406}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.9585805, \"EndTime\": 1652798599.9586005, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3429430791681463, \"count\": 1, \"min\": 0.3429430791681463, \"max\": 0.3429430791681463}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.958688, \"EndTime\": 1652798599.9587083, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3378784540349787, \"count\": 1, \"min\": 0.3378784540349787, \"max\": 0.3378784540349787}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.958827, \"EndTime\": 1652798599.9588492, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34238265991210937, \"count\": 1, \"min\": 0.34238265991210937, \"max\": 0.34238265991210937}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #quality_metric: host=algo-1, epoch=7, train binary_classification_cross_entropy_objective <loss>=0.3307119404185902\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=binary_classification_cross_entropy_objective, value=0.32950421836159444\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] Epoch 7: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] Saving model for epoch: 7\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] Saved checkpoint to \"/tmp/tmpxv7r_arr/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #progress_metric: host=algo-1, completed 53.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.5614457, \"EndTime\": 1652798599.971185, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 194336.0, \"count\": 1, \"min\": 194336, \"max\": 194336}, \"Total Batches Seen\": {\"sum\": 196.0, \"count\": 1, \"min\": 196, \"max\": 196}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:19 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=55602.907024073545 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:20.233] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 19, \"duration\": 262, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.2340603, \"EndTime\": 1652798600.234154, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3294374639337713, \"count\": 1, \"min\": 0.3294374639337713, \"max\": 0.3294374639337713}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.2344887, \"EndTime\": 1652798600.234518, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.330296254938299, \"count\": 1, \"min\": 0.330296254938299, \"max\": 0.330296254938299}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.23462, \"EndTime\": 1652798600.2346427, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32839124644886364, \"count\": 1, \"min\": 0.32839124644886364, \"max\": 0.32839124644886364}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.234838, \"EndTime\": 1652798600.234867, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3303472498113459, \"count\": 1, \"min\": 0.3303472498113459, \"max\": 0.3303472498113459}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.2349346, \"EndTime\": 1652798600.2349544, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3384553722034801, \"count\": 1, \"min\": 0.3384553722034801, \"max\": 0.3384553722034801}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.2350144, \"EndTime\": 1652798600.2350318, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3432161657159979, \"count\": 1, \"min\": 0.3432161657159979, \"max\": 0.3432161657159979}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.2351377, \"EndTime\": 1652798600.2351594, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3379410344904119, \"count\": 1, \"min\": 0.3379410344904119, \"max\": 0.3379410344904119}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.235221, \"EndTime\": 1652798600.235239, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3447657581676136, \"count\": 1, \"min\": 0.3447657581676136, \"max\": 0.3447657581676136}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #quality_metric: host=algo-1, epoch=8, train binary_classification_cross_entropy_objective <loss>=0.3294374639337713\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=binary_classification_cross_entropy_objective, value=0.32839124644886364\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] Epoch 8: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] Saving model for epoch: 8\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] Saved checkpoint to \"/tmp/tmphv423voh/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798599.97154, \"EndTime\": 1652798600.2436132, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 217128.0, \"count\": 1, \"min\": 217128, \"max\": 217128}, \"Total Batches Seen\": {\"sum\": 219.0, \"count\": 1, \"min\": 219, \"max\": 219}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=83739.19105395152 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:20.499] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 21, \"duration\": 255, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.4995024, \"EndTime\": 1652798600.4995668, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32837371826171874, \"count\": 1, \"min\": 0.32837371826171874, \"max\": 0.32837371826171874}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.499667, \"EndTime\": 1652798600.4996886, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32926532537286934, \"count\": 1, \"min\": 0.32926532537286934, \"max\": 0.32926532537286934}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.499747, \"EndTime\": 1652798600.4997635, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3274441375732422, \"count\": 1, \"min\": 0.3274441375732422, \"max\": 0.3274441375732422}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.4998162, \"EndTime\": 1652798600.499833, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32926690396395597, \"count\": 1, \"min\": 0.32926690396395597, \"max\": 0.32926690396395597}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.4998882, \"EndTime\": 1652798600.499905, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33751822592995384, \"count\": 1, \"min\": 0.33751822592995384, \"max\": 0.33751822592995384}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.499964, \"EndTime\": 1652798600.4999819, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34267515702681106, \"count\": 1, \"min\": 0.34267515702681106, \"max\": 0.34267515702681106}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.5000372, \"EndTime\": 1652798600.500053, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3371134393865412, \"count\": 1, \"min\": 0.3371134393865412, \"max\": 0.3371134393865412}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.5001075, \"EndTime\": 1652798600.5001237, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34343436085094103, \"count\": 1, \"min\": 0.34343436085094103, \"max\": 0.34343436085094103}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #quality_metric: host=algo-1, epoch=9, train binary_classification_cross_entropy_objective <loss>=0.32837371826171874\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=binary_classification_cross_entropy_objective, value=0.3274441375732422\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] Epoch 9: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] Saving model for epoch: 9\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] Saved checkpoint to \"/tmp/tmpe0_63v4e/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #progress_metric: host=algo-1, completed 66.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.2438843, \"EndTime\": 1652798600.5092776, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 239920.0, \"count\": 1, \"min\": 239920, \"max\": 239920}, \"Total Batches Seen\": {\"sum\": 242.0, \"count\": 1, \"min\": 242, \"max\": 242}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=85827.28594527865 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:20.799] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 288, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.7996821, \"EndTime\": 1652798600.7997496, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3274587721391158, \"count\": 1, \"min\": 0.3274587721391158, \"max\": 0.3274587721391158}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.8001623, \"EndTime\": 1652798600.800192, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3283468336625533, \"count\": 1, \"min\": 0.3283468336625533, \"max\": 0.3283468336625533}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.8005672, \"EndTime\": 1652798600.800599, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32661629832874645, \"count\": 1, \"min\": 0.32661629832874645, \"max\": 0.32661629832874645}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.800906, \"EndTime\": 1652798600.8010566, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32831836769797584, \"count\": 1, \"min\": 0.32831836769797584, \"max\": 0.32831836769797584}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.8011358, \"EndTime\": 1652798600.8011572, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3376585637872869, \"count\": 1, \"min\": 0.3376585637872869, \"max\": 0.3376585637872869}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.80124, \"EndTime\": 1652798600.8012576, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3437792538729581, \"count\": 1, \"min\": 0.3437792538729581, \"max\": 0.3437792538729581}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.8013093, \"EndTime\": 1652798600.8013265, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3374435729980469, \"count\": 1, \"min\": 0.3374435729980469, \"max\": 0.3374435729980469}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.8013892, \"EndTime\": 1652798600.8014057, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3439335660067472, \"count\": 1, \"min\": 0.3439335660067472, \"max\": 0.3439335660067472}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #quality_metric: host=algo-1, epoch=10, train binary_classification_cross_entropy_objective <loss>=0.3274587721391158\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=binary_classification_cross_entropy_objective, value=0.32661629832874645\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] Epoch 10: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] Saving model for epoch: 10\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] Saved checkpoint to \"/tmp/tmpcf4cnjch/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #progress_metric: host=algo-1, completed 73.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.5096202, \"EndTime\": 1652798600.8111868, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 262712.0, \"count\": 1, \"min\": 262712, \"max\": 262712}, \"Total Batches Seen\": {\"sum\": 265.0, \"count\": 1, \"min\": 265, \"max\": 265}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:20 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=75544.31928890968 records/second\u001b[0m\n",
      "\n",
      "2022-05-17 14:43:29 Uploading - Uploading generated training model\u001b[34m[2022-05-17 14:43:21.076] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 25, \"duration\": 264, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.0766447, \"EndTime\": 1652798601.0767097, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.326654091574929, \"count\": 1, \"min\": 0.326654091574929, \"max\": 0.326654091574929}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.0768096, \"EndTime\": 1652798601.076966, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32750467751242895, \"count\": 1, \"min\": 0.32750467751242895, \"max\": 0.32750467751242895}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.077121, \"EndTime\": 1652798601.077148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3258788077614524, \"count\": 1, \"min\": 0.3258788077614524, \"max\": 0.3258788077614524}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.0773203, \"EndTime\": 1652798601.077344, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32745798284357247, \"count\": 1, \"min\": 0.32745798284357247, \"max\": 0.32745798284357247}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.0774891, \"EndTime\": 1652798601.0775135, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3362841616543856, \"count\": 1, \"min\": 0.3362841616543856, \"max\": 0.3362841616543856}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.077653, \"EndTime\": 1652798601.0776753, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34340182078968395, \"count\": 1, \"min\": 0.34340182078968395, \"max\": 0.34340182078968395}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.0777366, \"EndTime\": 1652798601.077754, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33525885009765627, \"count\": 1, \"min\": 0.33525885009765627, \"max\": 0.33525885009765627}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.077975, \"EndTime\": 1652798601.077998, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3440512958873402, \"count\": 1, \"min\": 0.3440512958873402, \"max\": 0.3440512958873402}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #quality_metric: host=algo-1, epoch=11, train binary_classification_cross_entropy_objective <loss>=0.326654091574929\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=11, criteria=binary_classification_cross_entropy_objective, value=0.3258788077614524\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Epoch 11: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Saving model for epoch: 11\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Saved checkpoint to \"/tmp/tmpquk8rndo/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798600.8121994, \"EndTime\": 1652798601.0871236, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 285504.0, \"count\": 1, \"min\": 285504, \"max\": 285504}, \"Total Batches Seen\": {\"sum\": 288.0, \"count\": 1, \"min\": 288, \"max\": 288}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=82844.20292356916 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:21.396] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 27, \"duration\": 309, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.3971107, \"EndTime\": 1652798601.3971646, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32593492126464846, \"count\": 1, \"min\": 0.32593492126464846, \"max\": 0.32593492126464846}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.397304, \"EndTime\": 1652798601.3973272, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3267244900790128, \"count\": 1, \"min\": 0.3267244900790128, \"max\": 0.3267244900790128}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.3973858, \"EndTime\": 1652798601.397399, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32521321938254616, \"count\": 1, \"min\": 0.32521321938254616, \"max\": 0.32521321938254616}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.3974555, \"EndTime\": 1652798601.397473, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3266671447753906, \"count\": 1, \"min\": 0.3266671447753906, \"max\": 0.3266671447753906}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.3975136, \"EndTime\": 1652798601.3975294, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33622460521351205, \"count\": 1, \"min\": 0.33622460521351205, \"max\": 0.33622460521351205}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.397582, \"EndTime\": 1652798601.3975985, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3447340018532493, \"count\": 1, \"min\": 0.3447340018532493, \"max\": 0.3447340018532493}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.3976412, \"EndTime\": 1652798601.397657, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3364405059814453, \"count\": 1, \"min\": 0.3364405059814453, \"max\": 0.3364405059814453}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.3977094, \"EndTime\": 1652798601.397726, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3450776991410689, \"count\": 1, \"min\": 0.3450776991410689, \"max\": 0.3450776991410689}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #quality_metric: host=algo-1, epoch=12, train binary_classification_cross_entropy_objective <loss>=0.32593492126464846\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=12, criteria=binary_classification_cross_entropy_objective, value=0.32521321938254616\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Epoch 12: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Saving model for epoch: 12\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Saved checkpoint to \"/tmp/tmp4c98xlyp/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #progress_metric: host=algo-1, completed 86.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.0876164, \"EndTime\": 1652798601.4061737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 308296.0, \"count\": 1, \"min\": 308296, \"max\": 308296}, \"Total Batches Seen\": {\"sum\": 311.0, \"count\": 1, \"min\": 311, \"max\": 311}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=71507.1698737584 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:21.688] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 29, \"duration\": 281, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.688323, \"EndTime\": 1652798601.688388, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32528536571155897, \"count\": 1, \"min\": 0.32528536571155897, \"max\": 0.32528536571155897}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.6884851, \"EndTime\": 1652798601.688506, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32599713412198156, \"count\": 1, \"min\": 0.32599713412198156, \"max\": 0.32599713412198156}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.6885598, \"EndTime\": 1652798601.6885762, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3246077270507812, \"count\": 1, \"min\": 0.3246077270507812, \"max\": 0.3246077270507812}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.6886263, \"EndTime\": 1652798601.6886408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3259338614723899, \"count\": 1, \"min\": 0.3259338614723899, \"max\": 0.3259338614723899}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.688685, \"EndTime\": 1652798601.6886976, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3357665224942294, \"count\": 1, \"min\": 0.3357665224942294, \"max\": 0.3357665224942294}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.6887445, \"EndTime\": 1652798601.6887596, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3425939913662997, \"count\": 1, \"min\": 0.3425939913662997, \"max\": 0.3425939913662997}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.688806, \"EndTime\": 1652798601.6888216, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3348696080988104, \"count\": 1, \"min\": 0.3348696080988104, \"max\": 0.3348696080988104}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.6888669, \"EndTime\": 1652798601.6888764, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34321493807705966, \"count\": 1, \"min\": 0.34321493807705966, \"max\": 0.34321493807705966}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #quality_metric: host=algo-1, epoch=13, train binary_classification_cross_entropy_objective <loss>=0.32528536571155897\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=13, criteria=binary_classification_cross_entropy_objective, value=0.3246077270507812\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Epoch 13: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Saving model for epoch: 13\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Saved checkpoint to \"/tmp/tmp0imhbwxi/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #progress_metric: host=algo-1, completed 93.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.4069734, \"EndTime\": 1652798601.6991043, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 331088.0, \"count\": 1, \"min\": 331088, \"max\": 331088}, \"Total Batches Seen\": {\"sum\": 334.0, \"count\": 1, \"min\": 334, \"max\": 334}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=77980.92072009313 records/second\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:21.973] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 31, \"duration\": 272, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.9738708, \"EndTime\": 1652798601.9739313, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32469359241832385, \"count\": 1, \"min\": 0.32469359241832385, \"max\": 0.32469359241832385}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.9742951, \"EndTime\": 1652798601.9743192, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3253151980313388, \"count\": 1, \"min\": 0.3253151980313388, \"max\": 0.3253151980313388}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.9746397, \"EndTime\": 1652798601.9746616, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.32405321433327416, \"count\": 1, \"min\": 0.32405321433327416, \"max\": 0.32405321433327416}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.9747837, \"EndTime\": 1652798601.9748058, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3252495283647017, \"count\": 1, \"min\": 0.3252495283647017, \"max\": 0.3252495283647017}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.9748669, \"EndTime\": 1652798601.9748845, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33549475929953837, \"count\": 1, \"min\": 0.33549475929953837, \"max\": 0.33549475929953837}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.974941, \"EndTime\": 1652798601.9749587, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.34498468295010654, \"count\": 1, \"min\": 0.34498468295010654, \"max\": 0.34498468295010654}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.9750123, \"EndTime\": 1652798601.9750285, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.334920879017223, \"count\": 1, \"min\": 0.334920879017223, \"max\": 0.334920879017223}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.9750807, \"EndTime\": 1652798601.9750972, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3449547354958274, \"count\": 1, \"min\": 0.3449547354958274, \"max\": 0.3449547354958274}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #quality_metric: host=algo-1, epoch=14, train binary_classification_cross_entropy_objective <loss>=0.32469359241832385\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #early_stopping_criteria_metric: host=algo-1, epoch=14, criteria=binary_classification_cross_entropy_objective, value=0.32405321433327416\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Epoch 14: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Saving model for epoch: 14\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] Saved checkpoint to \"/tmp/tmplns54fc8/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798601.7001355, \"EndTime\": 1652798601.9841259, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 353880.0, \"count\": 1, \"min\": 353880, \"max\": 353880}, \"Total Batches Seen\": {\"sum\": 357.0, \"count\": 1, \"min\": 357, \"max\": 357}, \"Max Records Seen Between Resets\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Max Batches Seen Between Resets\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 22792.0, \"count\": 1, \"min\": 22792, \"max\": 22792}, \"Number of Batches Since Last Reset\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}}}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 INFO 140480837568320] #throughput_metric: host=algo-1, train throughput=80209.57327818028 records/second\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 WARNING 140480837568320] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:21 WARNING 140480837568320] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:21.992] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 33, \"duration\": 7, \"num_examples\": 1, \"num_bytes\": 480000}\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:22.204] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 209, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m[2022-05-17 14:43:22.331] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 101, \"num_examples\": 23, \"num_bytes\": 10940160}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #train_score (algo-1) : ('binary_classification_cross_entropy_objective', 0.3231222863028283)\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #train_score (algo-1) : ('binary_classification_accuracy', 0.84994734994735)\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #train_score (algo-1) : ('binary_f_1.000', 0.6498771498771498)\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #train_score (algo-1) : ('precision', 0.7400326416414083)\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #train_score (algo-1) : ('recall', 0.5793027924803796)\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #train_score (algo-1) : ('roc_auc_score', 0.9046011252175056)\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #train_score (algo-1) : ('binary_balanced_accuracy', 0.5)\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #train_score (algo-1) : ('binary_log_loss', 0.694595751376812)\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #quality_metric: host=algo-1, train binary_classification_cross_entropy_objective <loss>=0.3231222863028283\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.84994734994735\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.6498771498771498\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #quality_metric: host=algo-1, train precision <score>=0.7400326416414083\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #quality_metric: host=algo-1, train recall <score>=0.5793027924803796\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #quality_metric: host=algo-1, train roc_auc_score <score>=0.9046011252175056\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #quality_metric: host=algo-1, train binary_balanced_accuracy <score>=0.5\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] #quality_metric: host=algo-1, train binary_log_loss <score>=0.694595751376812\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.005, \"wd\": 0.0001, \"l1\": 0.0, \"lr_scheduler_step\": 10, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 0.0001}\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] Saved checkpoint to \"/tmp/tmpppley8s8/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/17/2022 14:43:22 INFO 140480837568320] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1652798596.8546507, \"EndTime\": 1652798602.384899, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 218.5521125793457, \"count\": 1, \"min\": 218.5521125793457, \"max\": 218.5521125793457}, \"epochs\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"check_early_stopping.time\": {\"sum\": 17.83442497253418, \"count\": 15, \"min\": 0.9267330169677734, \"max\": 1.5337467193603516}, \"update.time\": {\"sum\": 4830.869674682617, \"count\": 15, \"min\": 260.32567024230957, \"max\": 422.9409694671631}, \"finalize.time\": {\"sum\": 396.014928817749, \"count\": 1, \"min\": 396.014928817749, \"max\": 396.014928817749}, \"setuptime\": {\"sum\": 29.308319091796875, \"count\": 1, \"min\": 29.308319091796875, \"max\": 29.308319091796875}, \"totaltime\": {\"sum\": 5812.49213218689, \"count\": 1, \"min\": 5812.49213218689, \"max\": 5812.49213218689}}}\u001b[0m\n",
      "\n",
      "2022-05-17 14:43:57 Completed - Training job completed\n",
      "Training seconds: 113\n",
      "Billable seconds: 113\n"
     ]
    }
   ],
   "source": [
    "linear.fit({'train': s3_train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy, previsões e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "linear_classifier = linear.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "linear_classifier.serializer = CSVSerializer()\n",
    "linear_classifier.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9769, 108)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = linear_classifier.predict(X_teste)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes = np.array([r['predicted_label'] for r in results['predictions']])\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste = np.array(y_teste).astype(int)\n",
    "y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8456341488381616"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6898,  509],\n",
       "       [ 999, 1363]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_teste, previsoes)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8261"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6898 + 1363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1508"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "999 + 509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      7407\n",
      "           1       0.73      0.58      0.64      2362\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.80      0.75      0.77      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_teste, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
